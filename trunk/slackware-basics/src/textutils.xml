<!-- $Id: textutils.xml,v 1.4 2004/12/04 15:59:09 daniel Exp $ -->

<chapter> <?dbhtml filename="textutils.html"?>
  <title>Text Utilities</title>

  <sect1>
    <title>Introduction</title>

    <para>
      On of the central ideas of UNIX(-like) operating systems is that 
      <quote>everything is a file</quote>. Even devices can be treated
      as a file. Basically there are three types of files in UNIX:
    </para>

    <itemizedlist>
      <listitem>
        <para>
          <emphasis role="bold">Binary files</emphasis>, for example
          executables, and libraries.
        </para>
       </listitem>
      <listitem>
        <para>
          <emphasis role="bold">Device files</emphasis>, for example
          <filename>/dev/zero</filename>, and <filename>/dev/hda</filename>.
        </para>
      </listitem>
      <listitem>
        <para>
          <emphasis role="bold">Text files</emphasis>, pretty much
          anything else.
        </para>
      </listitem>
    </itemizedlist>

    <para>
      Due to the fact that text files have such an important role in
      UNIX-like operating systems, like GNU/Linux, this book has a separate
      chapter dedicated to the subject of processing text files. In
      the beginning its use may not be that obvious, but once you get
      used to these tools you will see that you will probably use some
      of these tools on a daily basis.
    </para>
    
    <note>
      <para>
        This chapter relies heavily on the use of pipes and redirection,
	so it it a good idea to read <xref linkend="redirection-and-pipes" />
	if you have not done that yet.
      </para>
    </note>
  </sect1>

  <sect1>
    <title>The basics</title> <!-- XXX - Not really inspiring ;) -->

    <sect2>
      <title>cat</title>
      
      <para>
        The <command>cat</command> command is one of the simplest commands
        around. Its default behaviour is just to send anything it receives
        on the standard input to the standard input until the end of file
	character (^D) is sent to the standard input. You can see this
        by executing cat, and entering some text:
      </para>
      
      <screen>
$ <command>cat</command>
<command>Hello world!</command>
Hello world!
<command>Testing... 1 2 3</command>
Testing... 1 2 3
      </screen>
      
      <para>
        You can also concatenate files with <command>cat</command>, by
	providing the files you would like to concatenate as an argument. 
	The concatenated files will be sent to the standard output:
      </para>
      
      <screen>
$ <command>cat test1</command>
This is the content of test1.
$ <command>cat test2</command>
This is the content of test2.
$ <command>cat test1 test2</command>
This is the content of test1.
This is the content of test2.
      </screen>
      
      <para>
        As you can see it is also possible to send a file to the standard
	output by specifying one file as <command>cat</command>'s argument.
	This is an alternative to redirection. For example, one could
	either of these command:
      </para>
      
      <screen>
$ <command>less &lt; test1</command>
$ <command> cat test1 | less</command>
      </screen>    
    </sect2>
    
    <sect2>
      <title>echo</title>
      
      <para>
        The <command>echo</command> is used to send something to the
	standard output by specifying it as an argument to 
	<command>echo</command>. For example, one could use echo
	to send a simple message to the standard output:
      </para>
      
      <screen>
$ <command>echo "Hello world!"</command>
Hello world!
      </screen>
    </sect2>
    
    <sect2>
      <title>wc</title>
      
      <para>
        One of the common things people often want to do with a text
	is counting the number of words, or lines in a text. The
	<command>wc</command> command can be used for this purpose.
	The file to be counted can be specified as an argument to
	<command>wc</command>
      </para>
      
      <screen>
$ <command>wc essay.txt</command>
 174 1083 8088 essay.txt
      </screen>
      
      <para>
        As you can see the default output returns three numbers. These
	are (in order): the <emphasis>number of lines</emphasis>, the
	<emphasis>number of words</emphasis>, and the 
	<emphasis>number of characters</emphasis>. It is also possibly
	to return only one of these numbers, with respectively
	<parameter>-l</parameter>, <parameter>-w</parameter>, and
	<parameter>-m</parameter>. For example, if we only want to
	know the number of lines in the file, we could do the
	following:
      </para>
      
      <screen>
$ <command>wc -l essay.txt</command>
174 essay.txt
      </screen>
      
      <para>
        In some situations you might want to use the output of
	<command>wc</command> in a pipeline, or as an argument to another
	command. The problem with specifying the file name as an argument
	is that <command>wc</command> will also show the name of the
	file (as you can see in the example above). You can work around
	this behavior by redirecting the file contents to 
	<command>wc</command>. For example:
      </para>
      
      <screen>
$ <command> wc -l &lt; essay.txt</command>
174
      </screen>
    </sect2>
    
    <sect2 id="tr">
      <title>tr</title>
      
      <para>
        The <command>tr</command> is used to translate or delete
	characters. All uses of <command>tr</command> require one or
	two sets. A set is a string of characters. You can specify
	most characters in a set. The <command>tr</command>(1)
	manual page provides an overview of some character sequences
	with a special meaning. <xref linkend="tr-special-sequences" /> 
	describes some of the fequently used special character sequences.
      </para>
      
      <table id="tr-special-sequences">
        <title>Special tr character sequences</title>
        <tgroup cols="2">
	  <thead>
	    <row>
	      <entry>Sequence</entry><entry>Meaning</entry>
	    </row>
	  </thead>
	  <tbody>
	    <row>
	      <entry>\\</entry>
	      <entry>backslash (\)</entry>
	    </row>
	    <row>
	      <entry>\n</entry>
	      <entry>new line</entry>
	    </row>
	    <row>
	      <entry>char1-char2</entry>
	      <entry>
	        All characters from <emphasis>char1</emphasis> to 
		<emphasis>char2</emphasis> (e.g. <quote>a-z</quote>)
	      </entry>
	    </row>
	    <row>
	      <entry>[:alnum:]</entry>
	      <entry>All alphanumeric characters</entry>
	    </row>
	    <row>
	      <entry>
	        [:alpha:]
	      </entry>
	      <entry>
	        All letters in the alphabet
	      </entry>
	    </row>
	    <row>
	      <entry>
	        [:punct:]
	      </entry>
	      <entry>
	        Punctuation characters
	      </entry>
	    </row>
	  </tbody>
	</tgroup>
      </table>
      
      <para>
        Characters can be deleted from one text with the 
	<parameter>-d</parameter>, and a set that specifies the characters
	that should be deleted. Let's start with an easy example: suppose
	that you want to remove all the new line characters from a text
	stored in <filename>text</filename>, and that you would like to
	redirect the output to a file named 
	<filename>text-continuous</filename>. Obviously, we need a set
	with only one character, namely the new line character, which
	is specified with <quote>\n</quote>. This can be accomplished
	with the following command:
      </para>
      
      <screen>
$ <command>cat text | tr -d "\n" > text-continuous</command>
      </screen>
      
      <para>
        It happens quite often that you want to delete everything, but
	the characters that are specified in a set. You can do this by
	using the <parameter>-c</parameter>, which automatically complements
	the specified set. For example, if you'd like to remove every
	character from a text, except for alphabetical characters, new
	lines, and spaces, you can use the <parameter>-c</parameter>,
	and the following set:
	<emphasis><quote>[:alpha:]\n </quote></emphasis>. Combined
	in a command it would look like this:
      </para>
      
      <screen>
$ <command>cat text | tr -c -d "[:alpha:]\n "</command>
      </screen>
      
      <para>
        Using <command>tr</command> for translating characters does not
	require any extra parameters, but two sets. In the two sets
	the first character of the first set is replaced with the first
	character of the second set, etc. Suppose that we use these
	two sets: <quote>abc</quote> and <quote>def</quote>. With these
	sets the following translations occur: <quote>a -> d</quote>,
	<quote>b -> e</quote>, and <quote>c -> f</quote>. If the first
	set is longer than the second set, then the second set is
	expanded by repeating the last character of the second set. If
	the second set is longer than the first set, extra characters
	in the second set are ignored.
      </para>
      
      <para>
        Translations can be useful for many purposes. For example, it
	can be used to make a wordlist from a text. This can be done
	by replacing all spaces with a newline:
      </para>
      
      <screen>
$ <command>cat essay.txt | tr " " "\n" | less</command>
      </screen>
      
      <para>
        As you can imagine the output might still contain non-alphabetic
	characters. We can combine the command above with the delete
	functionality of <command>tr</command> to make a wordlist without
	unwanted characters:
      </para>
      
      <screen>
$ <command>cat essay.txt | tr " " "\n" | tr -c -d "[:alpha:]\n" &gt; wordlist</command>
      </screen>
    </sect2>

    <sect2>
      <title>sort</title>
      
      <para>
        The <command>command</command> is used to sort lines in a
	file. To sort a text alphabetically, you can just pipe or
        redirect the data to <command>sort</command>. 
	<command>sort</command> also accepts file names as its
	parameters. When multiple files are specified, the files
	will be concatenated before sorting the lines. Suppose
	that you have a word list that is unordered, which is stored
	in the file <filename>wordlist_unsorted</filename>. You
	can sort the contents of the file, and output it to
	<filename>wordlist_sorted</filename> with:
      </para>
	
      <screen>
$ <command>sort wordlist_unsorted &gt; wordlist_sorted</command>
      </screen>
      
      <para>
        The <command>sort</command> accepts many different parameters,
	which are all described in the <command>sort</command>(1)
	manual page. An often-used parameter we will shortly discuss
	is <quote>-u</quote>. With this parameter only unique words
	will be sent to <emphasis>stdout</emphasis> (in other words:
	double occurences will be ignored). By combining
	<command>sort -u</command> and the <command>tr</command>, discussed 
	in <xref linkend="tr" />, you can make a sorted wordlist of a text:
      </para>
      
      <screen>
$ <command>cat essay.txt | tr " " "\n" | tr -c -d "[:alpha:]\n" | sort -u &gt; wordlist_sorted</command>
      </screen>
      
      <para>
        If the command listed in this example is combined with
	<command>wc</command>, one could count the size of the used
	vocabulary in the text. In the sorted word list each line represents 
	an unique word from the original text. So, we can count the total
	number of words that were used, by counting the total number of
	lines in the sorted list:
      </para>

      <screen>
$ <command>cat essay.txt | tr " " "\n" | tr -c -d "[:alpha:]\n" | sort -u | wc -l</command>
      </screen>
    </sect2>
    
    <sect2>
      <title>uniq</title>
      
      <para>
        The <command>uniq</command> can be compared to the <quote>-u</quote>
	parameter of the <command>sort</command>; it removes all but
	one entry of successive identical lines (in a sorted list). The
	main difference is that it provides some extra parameters that
	can be used to manipulate the output. The default behavior works
	like <command>sort -u</command>, and reduces duplicate entries: 
      </para>
      
      <screen>
$ <command>sort wordlist_unsorted | uniq &gt; wordlist_sorted</command>
      </screen>
      
      <para>
        To make a list of how often a line occurs in a text, one could
	count how many identical lines the sorted list contains of every
	line. Uniq can add the number of identical lines with the
	<quote>-c</quote> parameter. To make a list of how many times
	each word occurs in a text, you can combine <command>tr</command>,
	<command>sort</command>, and <command>uniq</command>:
      </para>
      
      <screen>
$ <command>cat essay.txt | tr " " "\n" | tr -c -d "[:alpha:]\n" | sort | uniq -c &gt; wordlist_sorted</command>
      </screen>
    </sect2>
  </sect1>

</chapter>
