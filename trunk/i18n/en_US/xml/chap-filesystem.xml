<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" version="5.0"
	 xmlns:xl="http://www.w3.org/1999/xlink"
	 xml:lang="en"
	 xml:id="chap-filesystem">
  <title>Files and directories</title>

  <sect1 xml:id="chap-filesystem-introduction">
    <title>Some theory</title>

    <para>
      Before we move on to look at practical filesystem operations, we
      are going to look at a more theoretical overview of how
      filesystems on UNIX-like systems work. Slackware Linux supports
      many different filesystems, but all these filesystems use
      virtually the same semantics. These semantics are provided
      through the <emphasis>Virtual Filesystem</emphasis> (VFS)
      layer, giving a generic layer for disk and network filesystems.
    </para>

    <sect2 xml:id="chap-filesystem-introduction-atoms">
      <title>inodes, directories and data</title>

      <para>
	The filesystem consists of two types of elements: data and
	metadata. The metadata describes the actual data blocks that
	are on the disk. Most filesystems use information nodes
	(inodes) to provide store metadata. Most filesystems store the
	following data in their inodes:
      </para>

      <table xml:id="chap-filesystem-introduction-atoms-inodes">
        <title>Common inode fields</title>
        <tgroup cols="2">
          <thead>
            <row>
              <entry>Field</entry>
              <entry>Description</entry>
            </row>
          </thead>
          <tbody>
            <row>
              <entry>mode</entry>
              <entry>The file permissions.</entry>
            </row>
            <row>
              <entry>uid</entry>
              <entry>The user ID of the owner of the file.</entry>
            </row>
            <row>
              <entry>gid</entry>
              <entry>The group ID of the group of the file.</entry>
            </row>
            <row>
              <entry>size</entry>
              <entry>Size of the file in bytes.</entry>
            </row>
            <row>
              <entry>ctime</entry>
              <entry>File creation time.</entry>
            </row>
            <row>
              <entry>mtime</entry>
              <entry>Time of the last file modification.</entry>
            </row>
            <row>
              <entry>links_count</entry>
              <entry>The number of links pointing to this inode.</entry>
            </row>
            <row>
              <entry>i_block</entry>
              <entry>Pointers to data blocks</entry>
            </row>
          </tbody>
        </tgroup>
      </table>

      <para>
	If you are not a UNIX or Linux afficiendo, these names will
	probably sound bogus to you, but we will clear them up in the
	following sections. At any rate, you can probably deduct the
	relation between inodes and data from this table, and
	specifically the <emphasis>i_block</emphasis> field: every
	inode has pointers to the data blocks that the inode provides
	information for. Together, the inode and data blocks are the
	actual file on the filesystem.
      </para>

      <para>
	You may wonder by now where the names of files (and
	directories) reside, since there is no file name field in the
	inode. Actually, the names of the files are separated from the
	inode and data blocks, which allows you to do groovy stuff,
	like giving the same file more than one name. The filenames
	are stored in so-called directory entries. These entries
	specify a filename and the inode of the file. Since
	directories are also represented by inodes, a directory
	structure can also be constructed in this manner.
      </para>

      <para>
	We can simply show how this all works by illustrating what the
	kernel does when we execute the command <command>cat
	/home/daniel/note.txt</command>
      </para>

      <orderedlist>
        <listitem>
	  <para>
	    The system reads the inode of the <filename>/</filename>
	    directory, checks if the user is allowed to access this
	    inode, and reads the data block to find the inode number
	    of the <filename>home</filename> directory.
	  </para>
        </listitem>
        <listitem>
          <para>
	    The system reads the inode of the
	    <filename>home</filename> directory, checks if the user is
	    allowed to access this inode, and reads the data block to
	    find the inode number of the <filename>daniel</filename>
	    directory. </para>
        </listitem>
        <listitem>
          <para>
	    The system reads the inode of the
	    <filename>daniel</filename> directory, checks if the user is
	    allowed to access this inode, and reads the data block to
	    find the inode number of the <filename>note.txt</filename>
	    file.
	  </para>
        </listitem>
        <listitem>
          <para>
	    The system reads the inode of the
	    <filename>note.txt</filename> file, checks if the user
	    is allowed to access this inode, and returns the data
	    blocks to <command>cat</command> through the
	    <emphasis>read()</emphasis> system call. </para>
        </listitem>
      </orderedlist>
    </sect2>

    <sect2 xml:id="chap-filesystem-introduction-permissions">
      <title>File permissions</title>

      <para>
	As we have described earlier, Linux is a multi-user
	system. This means that each user has his/her own files (that
	are usually located in the home directory). Besides that users
	can be members of a group, which may give the user additional
	privileges.
      </para>

      <para>
	As you have seen in the inode field table, every file has a
	owner and a group.  Traditional UNIX access control gives
	read, write, or executable permissions to the file owner, file
	group, and other users. These permissions are stored in the
	<emphasis>mode</emphasis> field of the inode. The mode field
	represents the file permissions as a four digit octal
	number. The first digit represents some special
	options, the second digit stores the owner permissions, the
	third the group permissions, and the fourth the permissions
	for other users. The permissions are established by digit by
	using or adding one of the number in <xref
	linkend="chap-filesystem-permissions-numbers"/>
      </para>

      <table xml:id="chap-filesystem-permissions-numbers">
        <title>Meaning of numbers in the mode octet</title>
        <tgroup cols="2">
          <thead>
            <row>
              <entry>Number</entry>
              <entry>Meaning</entry>
            </row>
          </thead>
          <tbody>
            <row>
              <entry>1</entry>
              <entry>Execute (x)</entry>
            </row>
            <row>
              <entry>2</entry>
              <entry>Write (w)</entry>
            </row>
            <row>
              <entry>4</entry>
              <entry>Read (r)</entry>
            </row>
          </tbody>
        </tgroup>
      </table>

      <para>
	Now, suppose that a file has mode <emphasis>0644</emphasis>,
	this means that the file is readable and writable by the owner
	(<emphasis>6</emphasis>), and readable by the file group
	(<emphasis>4</emphasis>) and others
	(<emphasis>4</emphasis>). </para>

      <para>
	Most users do not want to deal with octal numbers, so that is
	why many utilities can also deal with an alphabetic
	representation of file permissions. The letters that are
	listed in <xref
	linkend="chap-filesystem-permissions-numbers"/> between
	parentheses are used in this notation. In the following
	example information about a file with
	<emphasis>0644</emphasis> permissions is printed. The numbers
	are replaced by three rwx triplets (the first character can
	list special mode options).
      </para>

      <screen>
$ <userinput>ls -l note.txt</userinput>
-rw-r--r--  1 daniel daniel 5 Aug 28 19:39 note.txt
      </screen>

      <para>
	Over the years these traditional UNIX permissions have proven
	not to be sufficient in some cases. The POSIX 1003.1e
	specification aimed to extend the UNIX access control model
        with <emphasis>Access Control Lists</emphasis> (ACLs).
	Unfortunately this effort stalled,
        though some systems (like GNU/Linux) have implemented ACLs<footnote>
	<para>At the time of writing, ACLs were supported on ext2,
        ext3, and XFS filesystems</para> </footnote>. Access control
        lists follow the same semantics as normal file permissions,
        but give you the opportunity to add <emphasis>rwx</emphasis>
        triplets for additional users and groups. </para>

      <para>
	The following example shows the access control list of a
	file. As you can see, the permissions look like normal UNIX
	permissions (the access rights for the user, group, and others
	are specified). But there is also an additional entry for the
	user <emphasis>joe</emphasis>.
      </para>

      <programlisting>
user::rwx
user:joe:r--
group::---
mask::r--
other::---
      </programlisting>

      <para>
	To make matters even more complex (and sophisticated), some
	GNU/Linux systems add more fine-grained access control through
	Mandatory Access Control Frameworks (MAC) like SELinux and
	AppArmor. But these access control frameworks are beyond the
	scope of this book.
      </para>
    </sect2>

    <sect2 xml:id="chap-filesystems-introduction-links">
      <title>Links</title>

      <para>
	A directory entry that points to an inode is named a
	<emphasis>hard link</emphasis>.  Most files are only linked
	once, but nothing holds you from linking a file twice. This
	will increase the <emphasis>links_count</emphasis> field of
	the inode. This is a nice way for the system to see which
	inodes and data blocks are free to use. If links_count is set
	to zero, the inode is not referred to anymore, and can be
	reclaimed.
      </para>

      <figure xml:id="chap-filesystems-introduction-links-hardlink">
        <title>The structure of a hard link</title>

        <mediaobject>
          <imageobject>
            <imagedata format="PNG" fileref="../../images/hardlink.png"/>
          </imageobject>
          <imageobject>
            <imagedata format="SVG" fileref="../../images/hardlink.svg"/>
          </imageobject>
        </mediaobject>
      </figure>

      <para>
	Hard links have two limitations. First of all, hard links can
	not interlink between file systems, since they point to
	inodes. Every filesystem has its own inodes and corresponding
	inode numbers. Besides that, most filesystems do not allow you
	to create hard links to directories. Allowing creation of hard
	links to directories could produce directory loops,
	potentially leading to deadlocks and filesystem
	inconsistencies. In addition to that, most implementations of
	<command>rm</command> and <command>rmdir</command> do not know
	how to deal with such extra directory hard links.
      </para>

      <para>
        <emphasis>Symbolic links</emphasis> do not have these
        limitations, because they point to file names, rather than
        inodes. When the symbolic link is used, the operating system
        will follow the path to that link. Symbolic links can also
        refer to a file that does not exist, since it just contains a
        name. Such links are called dangling links.
      </para>

      <figure xml:id="chap-filesystems-introduction-links-symlink">
        <title>The structure of a symbolic link</title>

        <mediaobject>
          <imageobject>
            <imagedata format="PNG" fileref="../../images/symlink.png"/>
          </imageobject>
          <imageobject>
            <imagedata format="SVG" fileref="../../images/symlink.svg"/>
          </imageobject>
        </mediaobject>
      </figure>

      <note>
        <para>
	  If you ever get into system administration, it is good to be
	  aware of the security implications of hard links. If the
	  <filename>/home</filename> directory is on the same
	  filesystem as any system binaries, a user will be able to
	  create hard links to binaries.  In the case that a
	  vulnerable program is upgraded, the link in the user's home
	  directory will keep pointing to the old program binary,
	  effectively giving the user continuing access to a
	  vulnerable binary.
	</para>

        <para>
	  For this reason it is a good idea to put any directories
	  that users can write to on different filesystems. In
	  practice, this means that it is a good idea to put at least
	  <filename>/home</filename> and <filename>/tmp</filename> on
	  separate filesystems.
        </para>
      </note>
    </sect2>
  </sect1>

  <sect1 xml:id="chap-filesystems-analyzing">
    <title>Analyzing files</title>

    <para>
      Before going to some more adventurous venues, we will start
      with some file and directory usage basics.
    </para>

    <sect2 xml:id="chap-filesystems-analyzing-listing">
      <title>Listing files</title>

      <para>
	One of the most common things that you will want to do is to
	list all or certain files. The <command>ls</command> command
	serves this purpose very well. Using <command>ls</command>
	without any arguments will show the contents of the actual
	directory:
      </para>

      <screen>
$ <userinput>ls</userinput>
dns.txt  network-hosts.txt  papers
      </screen>

      <para>
	If you use a GNU/Linux distribution, you may also see some
	fancy coloring based on the type of file. The standard output
	is handy to skim through the contents of a directory, but if
	you want more information, you can use the <parameter
	class="command">-l</parameter> parameter. This provides a
	so-called long listing for each file:
      </para>

      <screen>
$ <userinput>ls -l</userinput>
total 36
-rw-rw-r--  1 daniel daniel 12235 Sep  4 15:56 dns.txt
-rw-rw-r--  1 daniel daniel  7295 Sep  4 15:56 network-hosts.txt
drwxrwxr-x  2 daniel daniel  4096 Sep  4 15:55 papers
      </screen>

      <para>
	This gives a lot more information about the three directory
	entries that we have found with <command>ls</command>.  The
	first column shows the file permissions. The line that shows
	the <filename>papers</filename> entry starts with a
	<quote>d</quote>, meaning that this entry represents a
	directory. The second column shows the number of hard links
	pointing to the inode that a directory entry points to. If
	this is higher than 1, there is some other filename for the
	same file. Directory entries usually have at least two hard
	links, namely the link in the parent directory and the link in
	the directory itself (each directory has a
	<filename>.</filename> entry, which refers to the directory
	itself). The third and the fourth columns list the file owner
	and group respectively. The fifth column contains the file
	size in bytes. The sixth column the last modification time and
	date of the file. And finally, the last column shows the name
	of this entry.
      </para>

      <para>
	Files that start with a period (.) will not be shown by most
	applications, including <command>ls</command>. You can list
	these files too, by adding the <parameter
	class="command">-a</parameter> option to
	<command>ls</command>:
      </para>

      <screen>
$ <userinput>ls -la</userinput>
total 60
drwxrwxr-x   3 daniel daniel  4096 Sep 11 10:01 .
drwx------  88 daniel daniel  4096 Sep 11 10:01 ..
-rw-rw-r--   1 daniel daniel 12235 Sep  4 15:56 dns.txt
-rw-rw-r--   1 daniel daniel  7295 Sep  4 15:56 network-hosts.txt
drwxrwxr-x   2 daniel daniel  4096 Sep  4 15:55 papers
-rw-rw-r--   1 daniel daniel     5 Sep 11 10:01 .settings
      </screen>

      <para>
	As you can see, three more entries have appeared. First of
	all, the <filename>.settings</filename> file is now
	shown. Besides that you can see two additional directory
	entries, <filename>.</filename> and
	<filename>..</filename>. These represent the current directory
	and the parent directory respectively.
      </para>

      <para>
	Earlier in this chapter (<xref
	linkend="chap-filesystem-introduction-atoms"/>) we talked
	about inodes. The inode number that a directory entry points
	to can be shown with the <parameter
	class="command">-i</parameter> parameter. Suppose that I have
	created a hard link to the inode that points to the same inode
	as <filename>dns.txt</filename>, they should have the same
	inode number. The following <command>ls</command> output shows
	that this is true:
      </para>

      <screen>
$ <userinput>ls -i dns*</userinput>
3162388 dns-newhardlink.txt
3162388 dns.txt
      </screen>
    </sect2>

    <sect2 xml:id="chap-filesystem-analyzing-file">
      <title>Determining the type of a file</title>

      <para>
	Sometimes you will need some help to determine the type of a
	file. This is where the <command>file</command> utility
	becomes handy. Suppose that I find a file named
	<filename>HelloWorld.class</filename> somewhere on my disk. I
	suppose that this is a file that holds Java bytecode, but we
	can use <command>file</command> to check this:
      </para>

      <screen>
$ <userinput>file HelloWorld.class</userinput>
HelloWorld.class: compiled Java class data, version 49.0
      </screen>

      <para>
	That is definitely Java bytecode. <command>file</command> is
	quite smart, and handles most things you throw at it. For
	instance, you could ask it to provide information about a
	device node:
      </para>

      <screen>
$ <userinput>file /dev/zero</userinput>
/dev/zero: character special (1/5)
      </screen>

      <para>
	Or a symbolic link:
      </para>

      <screen>
$ <userinput>file /usr/X11R6/bin/X</userinput>
/usr/X11R6/bin/X: symbolic link to `Xorg'
      </screen>

      <para>
	If you are rather interested in the file
	<filename>/usr/X11R6/bin/X</filename> links to, you can use
	the <parameter class="command">-L</parameter> option of
	<command>file</command>:
      </para>

      <screen>
$ <userinput>file -L /usr/X11R6/bin/X</userinput>
/usr/X11R6/bin/X: setuid writable, executable, regular file, no read permission
      </screen>

      <para>
	You may wonder why <command>file</command> can determine the
	file type relatively easy. Most files start of with a
	so-called <emphasis>magic number</emphasis>, this is a unique
	number that tells programs that can read the file what kind of
	file it is. The <command>file</command> program uses a file
	which describes many file types and their magic numbers.  For
	instance, the magic file on my system contains the following
	lines for Java compiled class files:
      </para>

      <programlisting>
# Java ByteCode
# From Larry Schwimmer (schwim@cs.stanford.edu)
0       belong          0xcafebabe      compiled Java class data,
>6      beshort x       version %d.
>4      beshort x       \b%d
      </programlisting>

      <para>
	This entry says that if a file starts with a long (32-bit)
	hexadecimal magic number <emphasis>0xcafebabe</emphasis><footnote>
          <para>Yeah, you can be creative with magic numbers
          too!</para> </footnote>, it is a file that holds
          <quote>compiled Java class data</quote>. The short that
          follows determines the class file format version.
      </para>
    </sect2>

    <sect2 xml:id="chap-filesystem-analyzing-integrity">
      <title>File integrity</title>

      <para>
	While we will look at more advanced file integrity checking
	later, <!-- XXX xref --> we will have a short look at the
	<command>cksum</command> utility. <command>cksum</command> can
	calculate a cyclic redundancy check (CRC) for an input
	file. This is a mathematically sound method for calculating a
	unique number for a file. You can use this number to check
	whether a file is unchanged (for example, after downloading a
	file from a server). You can specify the file to calculate a
	CRC for as a parameter to <command>cksum</command>, and
	<command>cksum</command> will print the CRC, the file size in
	bytes, and the file name:
      </para>

      <screen>
$ <userinput>cksum myfile</userinput>
1817811752 22638 myfile
      </screen>

      <para>
	Slackware Linux also provides utilities for calculating
	checksums based on one-way hashes (for instance MD5 or SHA-1).
	<!-- XXX - elaborate -->
      </para>
    </sect2>

    <sect2 xml:id="chap-filesystem-analyzing-viewing">
      <title>Viewing files</title>

      <para>
	Since most files on UNIX systems are usually text files, they
	are easy to view from a character-based terminal or terminal
	emulator. The most primitive way of looking at the contents of
	a file is by using <command>cat</command>.
	<command>cat</command> reads files that were specified as a
	parameter line by line, and will write the lines to the
	standard output. So, you can write the contents of the file
	<filename>note.txt</filename> to the terminal with
	<command>cat note.txt</command>. While some systems and most
	terminal emulators provide support for scrolling, this is not
	a practical way to view large files. You can pipe the output
	of <command>cat</command> to the <command>less</command>
	paginator:
      </para>

      <screen>
$ <userinput>cat note.txt | less</userinput>
      </screen>

      <para>
	or let <command>less</command> read the file directly:
      </para>

      <screen>
$ <userinput>less note.txt</userinput>
      </screen>

      <para>
	The <command>less</command> paginator lets you scroll forward
	and backward through a file. <xref
	linkend="chap-filesystem-analyzing-viewing-less-keys"/>
	provides an overview of the most important keys that are used
	to control <command>less</command>
      </para>

      <table xml:id="chap-filesystem-analyzing-viewing-less-keys">
        <title>less command keys</title>

        <tgroup cols="2" colsep="1" rowsep="1">
          <thead>
            <row>
              <entry>Key</entry>
              <entry>Description</entry>
            </row>
          </thead>
          <tbody>
            <row>
              <entry>j</entry>
              <entry>Scroll forward one line.</entry>
            </row>
            <row>
              <entry>k</entry>
              <entry>Scroll backwards one line.</entry>
            </row>
            <row>
              <entry>f</entry>
              <entry>Scroll forward one screen full of text.</entry>
            </row>
            <row>
              <entry>b</entry>
              <entry>Scroll backwards one screen full of text.</entry>
            </row>
            <row>
              <entry>q</entry>
              <entry>Quit less.</entry>
            </row>
            <row>
              <entry>g</entry>
              <entry>Jump to the beginning of the file.</entry>
            </row>
            <row>
              <entry>G</entry>
              <entry>Jump to the end of the file.</entry>
            </row>
            <row>
              <entry>/<emphasis>pattern</emphasis></entry>
              <entry> Search for the <link xl:href="#chap-textproc-regexps">regular expression</link>
                <emphasis>pattern</emphasis>. </entry>
            </row>
            <row>
              <entry>n</entry>
              <entry> Search for the next match of the previously specified regular expression.
              </entry>
            </row>
            <row>
              <entry>m<emphasis>letter</emphasis></entry>
              <entry> Mark the current position in the file with <emphasis>letter</emphasis>.
              </entry>
            </row>
            <row>
              <entry>'<emphasis>letter</emphasis></entry>
              <entry>Jump to the mark <emphasis>letter</emphasis></entry>
            </row>
          </tbody>
        </tgroup>
      </table>

      <para>
	The command keys that can be quantized can be prefixed by a
	number. For instance <emphasis>11j</emphasis> scrolls forward
	eleven lines, and <emphasis>3n</emphasis> searches the third
	match of the previously specified regular expression.
      </para>

      <para>
	Slackware Linux also provides an alternative to
	<command>less</command>, the older <quote>more</quote> command.
	We will not go into <emphasis>more</emphasis> here,
	<command>less</command> is more comfortable, and also more popular
	these days.
      </para>

    </sect2>

    <sect2 xml:id="chap-filesystem-analyzing-filesize">
      <title>File and directory sizes</title>

      <para>
	The <command>ls -l</command> output that we have seen earlier
	provides information about the size of a file. While this
	usually provides enough information about the size of files,
	you might want to gather information about collections of
	files or directories. This is where the <command>du</command>
	command comes in. By default, <command>du</command> prints the
	file size per directory. For example:
      </para>

      <screen>
$ <userinput>du ~/qconcord</userinput>
72      /home/daniel/qconcord/src
24      /home/daniel/qconcord/ui
132     /home/daniel/qconcord
      </screen>

      <para>
        By default, <command>du</command> represents the size in 1024
        byte units. You can explicitly specify that
        <command>du</command> should use 1024 byte units by adding the
        <parameter class="command" >-k</parameter> flag. This is useful
	for writing scripts, because some other systems default to
	using 512-byte blocks. For example:
      </para>

      <screen>
$ <userinput>du -k ~/qconcord</userinput>
72	/home/daniel/qconcord/src
24	/home/daniel/qconcord/ui
132	/home/daniel/qconcord
      </screen>

      <para>
	If you would also like to see per-file disk usage, you can add
	the <parameter class="command">-a</parameter> flag:
      </para>

      <screen>
$ <userinput>du -k -a ~/qconcord</userinput>
8       /home/daniel/qconcord/ChangeLog
8       /home/daniel/qconcord/src/concordanceform.h
8       /home/daniel/qconcord/src/textfile.cpp
12      /home/daniel/qconcord/src/concordancemainwindow.cpp
12      /home/daniel/qconcord/src/concordanceform.cpp
8       /home/daniel/qconcord/src/concordancemainwindow.h
8       /home/daniel/qconcord/src/main.cpp
8       /home/daniel/qconcord/src/textfile.h
72      /home/daniel/qconcord/src
12      /home/daniel/qconcord/Makefile
16      /home/daniel/qconcord/ui/concordanceformbase.ui
24      /home/daniel/qconcord/ui
8       /home/daniel/qconcord/qconcord.pro
132     /home/daniel/qconcord
      </screen>

      <para>
	You can also use the name of a file or a wildcard as a
	parameter. But this will not print the sizes of files in
	subdirectories, unless <parameter
	class="command">-a</parameter> is used:
      </para>

      <screen>
$ <userinput>du -k -a ~/qconcord/*</userinput>
8       /home/daniel/qconcord/ChangeLog
12      /home/daniel/qconcord/Makefile
8       /home/daniel/qconcord/qconcord.pro
8       /home/daniel/qconcord/src/concordanceform.h
8       /home/daniel/qconcord/src/textfile.cpp
12      /home/daniel/qconcord/src/concordancemainwindow.cpp
12      /home/daniel/qconcord/src/concordanceform.cpp
8       /home/daniel/qconcord/src/concordancemainwindow.h
8       /home/daniel/qconcord/src/main.cpp
8       /home/daniel/qconcord/src/textfile.h
72      /home/daniel/qconcord/src
16      /home/daniel/qconcord/ui/concordanceformbase.ui
24      /home/daniel/qconcord/ui
      </screen>

      <para>
	If you want to see the total sum of the disk usage of the
	files and subdirectories that a directory holds, use the
	<parameter class="command">-s</parameter> flag:
      </para>

      <screen>
$ <userinput>du -k -s ~/qconcord</userinput>
132     /home/daniel/qconcord
      </screen>
    </sect2>
  </sect1>

  <sect1 xml:id="chap-filesystem-directories">
    <title>Working with directories</title>

    <para>
      After having a bird's eye view of directories in <xref
      linkend="chap-filesystem-introduction-atoms"/>, we will have a
      look at some directory-related commands.
    </para>

    <sect2 xml:id="chap-filesystem-directories-listing">
      <title>Listing directories</title>

      <para>
	The <command>ls</command> command that we have looked at in
	<xref linkend="chap-filesystems-analyzing-listing"/> can also
	be used to list directories in various ways. As we have seen,
	the default <command>ls</command> output includes directories,
	and directories can be identified using the first output
	column of a long listing:
      </para>

      <screen>
$ <userinput>ls -l</userinput>
total 36
-rw-rw-r--  1 daniel daniel 12235 Sep  4 15:56 dns.txt
-rw-rw-r--  1 daniel daniel  7295 Sep  4 15:56 network-hosts.txt
drwxrwxr-x  2 daniel daniel  4096 Sep  4 15:55 papers
      </screen>

      <para>
	If a directory name, or if wildcards are specified,
	<command>ls</command> will list the contents of the directory,
	or the directories that match the wildcard respectively. For example,
	if there is a directory <filename>papers</filename>, <command>ls
	paper*</command> will list the contents of this directory
	<filename>paper</filename>. This is often annoying if you
	would just like to see the matches, and not the contents of
	the matching directories. The <parameter
	class="command">-d</parameter> avoid that this recursion
	happens:
      </para>

      <screen>
$ <userinput>ls -ld paper*</userinput>
drwxrwxr-x  2 daniel daniel  4096 Sep  4 15:55 papers
      </screen>

      <para>
	You can also recursively list the contents of a directory, and
	its subdirectories with the <parameter
	class="command">-R</parameter> parameter:
      </para>

      <screen>
$ <userinput>ls -R</userinput>
.:
dns.txt  network-hosts.txt  papers

./papers:
cs  phil

./papers/cs:
entr.pdf

./papers/phil:
logics.pdf
      </screen>
    </sect2>

    <sect2 xml:id="chap-filesystem-directories-management">
      <title>Creating and removing directories</title>

      <para>
	UNIX provides the <command>mkdir</command> command to create
	directories. If a relative path is specified, the directory is
	created in the current active directory. The basic syntax is
	very simple: <emphasis>mkdir &lt;name&gt;</emphasis>, for
	example:
      </para>

      <screen>
$ <userinput>mkdir mydir</userinput>
      </screen>

      <para>
	By default, <command>mkdir</command> only creates one
	directory level. So, if you use <command>mkdir</command> to
	create <filename>mydir/mysubdir</filename>,
	<command>mkdir</command> will fail if
	<filename>mydir</filename> does not exist already. If you
	would like to create both directories at once, use the
	<parameter class="command">-p</parameter> parameter:
      </para>

      <screen>
$ <userinput>mkdir -p mydir/mysubdir</userinput>
      </screen>

      <para>
	<command>rmdir</command> removes a directory. Its behavior is
	comparable to <command>mkdir</command>. <command>rmdir
	mydir/mysubdir</command> removes <filename>mydir/subdir</filename>,
	while <command>rmdir -p mydir/mysubdir</command> removes
	<filename>mydir/mysubdir</filename> and then
	<filename>mydir</filename>.
      </para>

      <para>
	If a subdirectory that we want to remove contains directory
	entries, <command>rmdir</command> will fail. If you would like
	to remove a directory, including all its contents, use the
	<command>rm</command> command instead. <!-- XXX - xref -->
      </para>
    </sect2>
  </sect1>

  <sect1 xml:id="chap-filesystem-managing">
    <title>Managing files and directories</title>

    <sect2 xml:id="chap-filesystem-managing-copying">
      <title>Copying</title>

      <para>
	Files and directories can be copied with the
	<command>cp</command> command. In its most basic syntax the
	source and the target file are specified. The following
	example will make a copy of <filename>file1</filename> named
	<filename>file2</filename>:
      </para>

      <screen>
$ <userinput>cp file1 file2</userinput>
      </screen>

      <para>
	It is not surprising that relative and absolute paths do also
	work:
      </para>

      <screen>
$ <userinput>cp file1 somedir/file2</userinput>
$ <userinput>cp file1 /home/joe/design_documents/file2</userinput>
      </screen>

      <para>
	You can also specify a directory as the second parameter. If
	this is the case, <command>cp</command> will make a copy of
	the file in that directory, giving it the same file name as
	the original file. If there is more than one parameter, the
	last parameter will be used as the target directory. For
	instance
      </para>

      <screen>
$ <userinput>cp file1 file2 somedir</userinput>
      </screen>

      <para>
	will copy both <filename>file1</filename> and
	<filename>file2</filename> to the directory
	<filename>somedir</filename>. You can not copy multiple files
	to one file. You will have to use <command>cat</command>
	instead: <!-- XXX href -->
      </para>

      <screen>
$ <userinput>cat file1 file2 > combined_file</userinput>
      </screen>

      <para>
	You can also use <command>cp</command> to copy directories, by
	adding the <parameter class="command">-R</parameter>. This
	will recursively copy a directory and all its
	subdirectories. If the target directory exists, the source
	directory or directories will be placed under the target
	directory. If the target directory does not exist, it will be
	created if there is only one source directory.
      </para>

      <screen>
$ <userinput>cp -r mytree tree_copy</userinput>
$ <userinput>mkdir trees</userinput>
$ <userinput>cp -r mytree trees</userinput>
      </screen>

      <para>
	After executing these commands, there are two copies of the directory
        <filename>mytree</filename>, <filename>tree_copy</filename> and
        <filename>trees/mytree</filename>. Trying to copy two directories to a nonexistent target
        directory will fail:
      </para>

      <screen>
$ <userinput>cp -R mytree mytree2 newdir</userinput>
usage: cp [-R [-H | -L | -P]] [-f | -i] [-pv] src target
       cp [-R [-H | -L | -P]] [-f | -i] [-pv] src1 ... srcN directory
      </screen>

      <note>
	<para>
	  Traditionally, the <parameter class="command">-r</parameter>
	  has been available on many UNIX systems to recursively copy
	  directories. However, the behavior of this parameter can be
	  implementation-dependent, and the Single UNIX Specification
	  version 3 states that it may be removed in future versions
	  of the standard.
	</para>
      </note>

      <para>
	When you are copying files recursively, it is a good idea to
	specify the behavior of what <command>cp</command> should do
	when a symbolic link is encountered explicitly, if you want
	to use <command>cp</command> in portable scripts. The
	Single UNIX Specification version 3 does not specify how they
	should be handled by default. If <parameter
	class="command">-P</parameter> is used, symbolic links will
	not be followed, effectively copying the link itself. If
	<parameter class="command">-H</parameter> is used, symbolic
	links specified as a parameter to <command>cp</command> may be
	followed, depending on the type and content of the file. If
	<parameter class="command">-L</parameter> is used, symbolic
	links that were specified as a parameter to
	<command>cp</command> and symbolic links that were encountered
	while copying recursively may be followed, depending on the
	content of the file.
      </para>

      <para>
	If you want to preserve the ownership, SGID/SUID bits, and the
	modification and access times of a file, you can use the
	<parameter>-p</parameter> flag. This will try to preserve
	these properties in the file or directory copy. Good
	implementations of <command>cp</command> provide some
	additional protection as well - if the target file already
	exists, it may not be overwritten if the relevant metadata
	could not be preserved.
      </para>
    </sect2>

    <sect2 xml:id="chap-filesystem-managing-moving">
      <title>Moving files and directories</title>

      <para>
	The UNIX command for moving files, <command>mv</command>, can
	move or rename files or directories. What actually happens
	depends on the location of the files or directories. If the
	source and destination files or directories are on the same
	filesystem, <command>mv</command> usually just creates new
	hard links, effectively renaming the files or directories. If
	both are on different filesystems, the files are actually
	copied, and the source files or directories are
	unlinked.
      </para>

      <para>
	The syntax of <command>mv</command> is comparable to
	<command>cp</command>. The most basic syntax renames
	<filename>file1</filename> to <filename>file2</filename>:
      </para>

      <screen>
$ <userinput>mv file1 file2</userinput>
      </screen>

      <para>
	The same syntax can be used for two directories as well, which
	will rename the directory given as the first parameter to the
	second parameter.
      </para>

      <para>
	When the last parameter is an existing directory, the file or
	directory that is specified as the first parameter, is copied
	to that directory. In this case you can specify multiple files
	or directories as well. For instance:
      </para>

      <screen>
$ <userinput>targetdir</userinput>
$ <userinput>mv file1 directory1 targetdir</userinput>
      </screen>

      <para> This creates the directory <filename>targetdir</filename>, and moves
        <filename>file1</filename> and <filename>directory1</filename> to this directory. </para>
    </sect2>

    <sect2 xml:id="chap-filesystem-managing-removing">
      <title>Removing files and directories</title>

      <para>
	Files and directories can be removed with the <citerefentry>
          <refentrytitle>rm</refentrytitle>
          <manvolnum>1</manvolnum>
        </citerefentry> command. This command unlinks files and directories. If there are no other
        links to a file, its inode and disk blocks can be reclaimed for new files. Files can be
        removed by providing the files that should be removed as a parameter to <citerefentry>
          <refentrytitle>rm</refentrytitle>
          <manvolnum>1</manvolnum>
        </citerefentry>. If the file is not writable, <citerefentry>
          <refentrytitle>rm</refentrytitle>
          <manvolnum>1</manvolnum>
        </citerefentry> will ask for confirmation. For instance, to remove
        <filename>file1</filename> and <filename>file2</filename>, you can execute: </para>

      <screen>
$ <userinput>rm file1 file2</userinput>
      </screen>

      <para>
	If you have to remove a large number of files that require a confirmation before they
        can be deleted, or if you want to use <citerefentry>
          <refentrytitle>rm</refentrytitle>
          <manvolnum>1</manvolnum>
        </citerefentry> to remove files from a script that will not be run on a terminal, add the
          <parameter class="command">-f</parameter> parameter to override the use of prompts. Files
        that are not writable, are deleted with the <filename>-f</filename> flag if the file
        ownership allows this. This parameter will also suppress printing of errors to
          <emphasis>stderr</emphasis> if a file that should be removed was not found. </para>

      <para> Directories can be removed recursively as well with the <parameter class="command"
        >-r</parameter> parameter. <citerefentry>
          <refentrytitle>rm</refentrytitle>
          <manvolnum>1</manvolnum>
        </citerefentry> will traverse the directory structure, unlinking and removing directories as
        they are encountered. The same semantics are used as when normal files are removed, as far
        as the <parameter class="command">-f</parameter> flag is concerned. To give a short example,
        you can recursively remove all files and directories in the <filename>notes</filename>
        directory with: </para>

      <screen>
$ <userinput>rm -r notes</userinput>
      </screen>

      <!-- XXX - describe -i flag? -->

      <para> Since <citerefentry>
          <refentrytitle>rm</refentrytitle>
          <manvolnum>1</manvolnum>
        </citerefentry> command uses the <citerefentry>
          <refentrytitle>unlink</refentrytitle>
          <manvolnum>2</manvolnum>
        </citerefentry> function, data blocks are not rewritten to an uninitialized state. The
        information in data blocks is only overwritten when they are reallocated and used at a later
        time. To remove files including their data blocks securely, some systems provide a <citerefentry>
          <refentrytitle>shred</refentrytitle>
          <manvolnum>1</manvolnum>
        </citerefentry> command that overwrites data blocks with random data. But this is not
        effective on many modern (journaling) filesystems, because they don't write data in place. </para>

      <para> The <citerefentry>
          <refentrytitle>unlink</refentrytitle>
          <manvolnum>1</manvolnum>
        </citerefentry> commands provides a one on one implementation of the <citerefentry>
          <refentrytitle>unlink</refentrytitle>
          <manvolnum>2</manvolnum>
        </citerefentry> function. It is of relatively little use, because it can not remove
        directories. </para>
    </sect2>
  </sect1>

  <sect1 xml:id="chap-filesystem-permissions">
    <title>Permissions</title>

    <para> We touched the subject of file and directory permissions in <xref
        linkend="chap-filesystem-introduction-permissions"/>. In this section, we will look at the <citerefentry>
        <refentrytitle>chown</refentrytitle>
        <manvolnum>1</manvolnum>
      </citerefentry> and <citerefentry>
        <refentrytitle>chmod</refentrytitle>
        <manvolnum>1</manvolnum>
      </citerefentry> commands, that are used to set the file ownership and permissions
      respectively. After that, we are going to look at a modern extension to permissions named
      Access Control Lists (ACLs). </para>

    <sect2 xml:id="chap-filesystem-permissions-ownership">
      <title>Changing the file ownership</title>

      <para> As we have seen earlier, every file has an owner (user) ID and a group ID stored in the
        inode. The <citerefentry>
          <refentrytitle>chown</refentrytitle>
          <manvolnum>1</manvolnum>
        </citerefentry> command can be used to set these fields. This can be done by the numeric
        IDs, or their names. For instance, to change the owner of the file
        <filename>note.txt</filename> to <emphasis>john</emphasis>, and its group to
        <emphasis>staff</emphasis>, the following command is used: </para>

      <screen>
$ <userinput>chown john:staff note.txt</userinput>
      </screen>

      <para> You can also omit either components, to only set one of both fields. If you want to set
        the user name, you can also omit the colon. So, the command above can be split up in two
        steps: </para>

      <screen>
$ <userinput>chown john note.txt</userinput>
$ <userinput>chown :staff note.txt</userinput>
      </screen>

      <para> If you want to change the owner of a directory, and all the files or directories it
        holds, you can add the <parameter class="command">-R</parameter> to <citerefentry>
          <refentrytitle>chown</refentrytitle>
          <manvolnum>1</manvolnum>
        </citerefentry>: </para>

      <screen>
$ <userinput>chown -R john:staff notes</userinput>
      </screen>

      <para> If user and group names were specified, rather than IDs, the names are converted by <citerefentry>
          <refentrytitle>chown</refentrytitle>
          <manvolnum>1</manvolnum>
        </citerefentry>. This conversion usually relies on the system-wide password database. If you
        are operating on a filesystem that uses another password database (e.g. if you mount a root
        filesystem from another system for recovery), it is often useful to change file ownership by
        the user or group ID. In this manner, you can keep the relevant user/group name to ID
        mappings in tact. So, changing the ownership of <filename>note</filename> to UID 1000 and
        GUID 1000 is done in the following (predictable) manner: </para>

      <screen>
$ <userinput>chown 1000:1000 note.txt</userinput>
      </screen>
    </sect2>

    <sect2 xml:id="chap-filesystem-permissions-permbits">
      <title>Changing file permission bits</title>

      <para> After reading the introduction to filesystem permissions in <xref
          linkend="chap-filesystem-introduction-permissions"/>, changing the permission bits that
        are stored in the inode is fairly easy with the <citerefentry>
          <refentrytitle>chmod</refentrytitle>
          <manvolnum>1</manvolnum>
        </citerefentry> command. <citerefentry>
          <refentrytitle>chmod</refentrytitle>
          <manvolnum>1</manvolnum>
        </citerefentry> accepts both numeric and symbolic representations of permissions.
        Representing the permissions of a file numerically is very handy, because it allows setting
        all relevant permissions tersely. For instance: </para>

      <screen>
$ <userinput>chmod 0644 note.txt</userinput>
      </screen>

      <para> Make <filename>note.txt</filename> readable and writable for the owner of the file, and
        readable for the file group and others. </para>

      <para> Symbolic permissions work with addition or subtraction of rights, and allow for
        relative changes of file permissions. The syntax for symbolic permissions is: </para>

      <screen>
[ugo][-+][rwxst]
      </screen>

      <para> The first component specifies the user classes to which the permission change applies
        (user, group or other). Multiple characters of this component can be combined. The second
        component takes away rights (<emphasis>-</emphasis>), or adds rights
        (<emphasis>+</emphasis>). The third component is the access specifier (read, write, execute,
        set UID/GID on execution, sticky). Multiple components can be specified for this component
        too. Let's look at some examples to clear this up: </para>

      <screen>
ug+rw        # Give read/write rights to the file user and group
chmod go-x   # Take away execute rights from the file group and others.
chmod ugo-wx # Disallow all user classes to write to the file and to
             # execute the file.
      </screen>

      <para> These commands can be used in the following manner with chmod: </para>

      <screen>
$ <userinput>chmod ug+rw note.txt</userinput>
$ <userinput>chmod go-x script1.sh</userinput>
$ <userinput>chmod ugo-x script2.sh</userinput>
      </screen>

      <para> Permissions of files and directories can be changed recursively with the <parameter
          class="command">-R</parameter>. The following command makes the directory
        <filename>notes</filename> world-readable, including its contents: </para>

      <screen>
$ <userinput>chmod -R ugo+r notes</userinput>
      </screen>

      <para> Extra care should be taken with directories, because the <emphasis>x</emphasis> flag
        has a special meaning in a directory context. Users that have execute rights on directories
        can access a directory. User that don't have execute rights on directories can not. Because
        of this particular behavior, it is often easier to change the permissions of a directory
        structure and its files with help of the <citerefentry>
          <refentrytitle>find</refentrytitle>
          <manvolnum>1</manvolnum>
        </citerefentry> command <!-- XXX xref -->. </para>

      <para> There are a few extra permission bits that can be set that have a special meaning. The
        SUID and SGID are the most interesting bits of these extra bits. These bits change the
        active user ID or group ID to that of the owner or group of the file when the file is
        executed. The <command>su(1)</command> command is a good example of a file that usually has
        the SUID bit set: </para>

      <screen>
$ <userinput>ls -l /bin/su</userinput>
-rwsr-xr-x  1 root root 60772 Aug 13 12:26 /bin/su
      </screen>

      <para> This means that the <command>su</command> command runs as the user
        <emphasis>root</emphasis> when it is executed. The SUID bit can be set with the
        <emphasis>s</emphasis> modifier. For instance, if the SUID bit was not set on
          <filename>/bin/su</filename> this could be done with: </para>

      <screen>
$ <userinput>chmod u+s /bin/su</userinput>
      </screen>

      <note>
        <para> Please be aware that the SUID and SGID bits have
        security implications. If a program with these bits set
        contain a bug, it may be exploited to get privileges of the
        file owner or group. For this reason it is good manner to keep
        the number of files with the SUID and SGID bits set to an
        absolute minimum. </para>
      </note>

      <para> The sticky bit is also interesting when it comes to
      directory. It disallows users to rename of unlink files that
      they do not own, in directories that they do have write access
      to. This is usually used on world-writeable directories, like
      the temporary directory (<filename>/tmp</filename>) on many UNIX
      systems. The sticky tag can be set with the
      <emphasis>t</emphasis> modifier: </para>

      <screen>
$ <userinput>chmod g+t /tmp</userinput>
      </screen>
    </sect2>

    <sect2 xml:id="chap-filesystem-permissions-umask">
      <title>File creation mask</title>

      <para>
	The question that remains is what initial permissions are used
	when a file is created.  This depends on two factors: the mode
	flag that was passed to the <emphasis>open(2)</emphasis>
	system call, that is used to create a file, and the active
	file creation mask. The file creation mask can be represented
	as an octal number. The effective permissions for creating the
	file are determined as <emphasis>mode &amp;
	~mask</emphasis>. Or, if represented in an octal fashion, you
	can substract the digits of the mask from the mode. For
	instance, if a file is created with permissions
	<emphasis>0666</emphasis> (readable and writable by the file
	user, file group, and others), and the effective file creation
	mask is <emphasis>0022</emphasis>, the effective file
	permission will be <emphasis>0644</emphasis>. Let's look at
	anothere example. Suppose that files are still created with
	<emphasis>0666</emphasis> permissions, and you are more
	paranoid, and want to take away all read and write permissions
	for the file group and others. This means you have to set the
	file creation mask to <emphasis>0066</emphasis>, because
	substracting <emphasis>0066</emphasis> from
	<emphasis>0666</emphasis> yields
	<emphasis>0600</emphasis>
      </para>
      
      <para>
        The effective file creation mask can be queried and set with
        the <command>umask</command> command, that is normally a
        built-in shell command. The effective mask can be printed by
        running <command>umask</command> without any parameters:
      </para>
      
      <screen>
$ <userinput>umask</userinput>
0002
      </screen>
      
      <para>
        The mask can be set by giving the octal mask number as a
        parameter. For instance:
      </para>
      
      <screen>
$ <userinput>umask 0066</userinput>
      </screen>
      
      <para>
        We can verify that this works by creating an empty file:
      </para>
      
      <screen>
$ <userinput>touch test</userinput>
$ <userinput>ls -l test</userinput>
-rw-------  1 daniel daniel 0 Oct 24 00:10 test2
      </screen>
      
    </sect2>

    <sect2 xml:id="chap-filesystem-permissions-acl">
      <title>Access Control Lists</title>

      <para>
	Access Control lists (<acronym>ACL</acronym>s) are an
	extension to traditional UNIX file permissions, that allow for
	more fine-grained access control. Most systems that support
	filesystem ACLs implement them as they were specified in the
	POSIX.1e and POSIX.2c draft specifications. Notable UNIX and
	UNIX-like systems that implement ACLs according to this draft
	are FreeBSD, Solaris, and Linux.
      </para>

      <para>
	As we have seen in <xref
	linkend="chap-filesystem-introduction-permissions" /> access
	control lists allows you to use read, write and execute
	triplets for additional users or groups. In contrast to the
	traditional file permissions, additional access control lists
	are note stored directly in the node, but in extended
	attributes that are associated with files. Two thing to be
	aware of when you use access control lists is that not all
	systems support them, and not all programs support them.
      </para>

      <sect3 xml:id="chap-filesystem-permissions-acl-reading">
	<title>Reading access control lists</title>

	<para>
	  On most systems that support ACLs, <command>ls</command>
	  uses a visual indicator to show that there are ACLs
	  associated with a file. For example:
	</para>

	<screen>
$ <userinput>ls -l index.html</userinput>
-rw-r-----+ 1 daniel daniel 3254 2006-10-31 17:11 index.html
	</screen>

	<para>
	  As you can see, the permissions column shows an additional
	  plus (<emphasis>+</emphasis>) sign. The permission bits do
	  not quite act like you expect them to be. We will get to
	  that in a minute.
	</para>

	<para>
	  The ACLs for a file can be queried with the
	  <command>getfacl</command> command:
	</para>

	<screen>
$ <userinput>getfacl index.html</userinput>
# file: index.html
# owner: daniel
# group: daniel
user::rw-
group::---
group:www-data:r--
mask::r--
other::---
	</screen>

	<para>
	  Most lines can be interpreted very easily: the file user has
	  read/write permissions, the file group no permissions, users
	  of the group <emphasis>www-data</emphasis> have read
	  permissions, and other users have no permissions. But why
	  does the group entry list no permissions for the file group,
	  while <command>ls</command> does? The secret is that if
	  there is a <emphasis>mask</emphasis> entry,
	  <command>ls</command> displays the value of the mask, rather
	  than the file group permissions.
	</para>

	<para>
	  The <emphasis>mask</emphasis> entry is used to restrict all
	  list entries with the exception of that of the file user,
	  and that for other users. It is best to memorize the
	  following rules for interpreting ACLs:
	</para>

	<itemizedlist>
	  <listitem>
	    <para>
	      The <emphasis>user::</emphasis> entry permissions
	      correspond with the permissions of the file owner.
	    </para>
	  </listitem>
	  <listitem>
	    <para>
	      The <emphasis>group::</emphasis> entry permissions
	      correspond with the permissions of the file group,
	      unless there is a <emphasis>mask::</emphasis> entry. If
	      there is a <emphasis>mask::</emphasis> entry, the
	      permissions of the group correspond to the group
	      entry with the the mask entry as the maximum of allowed
	      permissions (meaning that the group restrictions can be
	      more restrictive, but not more permissive).
	    </para>
	  </listitem>
	  <listitem>
	    <para>
	      The permissions of other users and groups correspond to
	      their <emphasis>user:</emphasis> and
	      <emphasis>group:</emphasis> entries, with the value of
	      <emphasis>mask::</emphasis> as their maximum
	      permissions.
	    </para>
	  </listitem>
	</itemizedlist>

	<para>
	  The second and third rules can clearly be observed if there
	  is a user or group that has more rights than the mask for
	  the file:
	</para>

	<screen>
$ <userinput>getfacl links.html</userinput>
# file: links.html
# owner: daniel
# group: daniel
user::rw-
group::rw-                      #effective:r--
group:www-data:rw-              #effective:r--
mask::r--
other::---
	</screen>

	<para>
	  Although read and write permissions are specified for the
	  file and <emphasis>www-data</emphasis> groups, both groups
	  will effectively only have read permission, because this is
	  the maximal permission that the mask allows.
	</para>

	<para>
	  Another aspect to pay attention to is the handling of ACLs
	  on directories. Access control lists can be added to
	  directories to govern access, but directories can also have
	  <emphasis>default ACLs</emphasis> which specify the initial
	  ACLs for files and directories created under that directory.
	</para>

	<para>
	  Suppose that the directory <filename>reports</filename> has
	  the following ACL:
	</para>

	<screen>
$ <userinput>getfacl reports</userinput>
# file: reports
# owner: daniel
# group: daniel
user::rwx
group::r-x
group:www-data:r-x
mask::r-x
other::---
default:user::rwx
default:group::r-x
default:group:www-data:r-x
default:mask::r-x
default:other::---
	</screen>

	<para>
	  New files that are created in the
	  <filename>reports</filename> directory get a ACL based on
	  the entries that have <emphasis>default:</emphasis> as a
	  prefix. For example:
	</para>

	<screen>
$ touch reports/test
$ getfacl reports/test
# file: reports/test
# owner: daniel
# group: daniel
user::rw-
group::r-x                      #effective:r--
group:www-data:r-x              #effective:r--
mask::r--
other::---
	</screen>

	<para>
	  As you can see, the default ACL was copied. The execute bit
	  is removed from the mask, because the new file was not
	  created with execute permissions.
	</para>
      </sect3>

      <sect3 xml:id="chap-filesystem-permissions-acl-setting">
	<title>Creating access control lists</title>

	<para>
	  The ACL for a file or directory can be changed with the
	  <command>setfacl</command> program. Unfortunately, the
	  usage of this program highly depends on the system that
	  is being used. To add to that confusion, at least one
	  important flag (<parameter class="command">-d</parameter>)
	  has a different meanings on different systems. One can
	  only hope that this command will get standardized.
	</para>

	<table xml:id="chap-filesystem-permissions-acl-setting-flags">
	  <title>System-specific <command>setfacl</command> flags</title>
	  
	  <tgroup cols="2">
	    <thead>
	      <row>
		<entry>Operation</entry>
		<entry>Linux</entry>
	      </row>
	    </thead>
	    <tbody>
	      <row>
		<entry>Set entries, removing all old entries</entry>
		<entry><parameter class="command">--set</parameter></entry>
	      </row>
	      <row>
		<entry>Modify entries</entry>
		<entry><parameter class="command">-m</parameter></entry>
	      </row>
	      <row>
		<entry>Modify default ACL entries</entry>
		<entry><parameter class="command">-d</parameter></entry>
	      </row>
	      <row>
		<entry>Delete entry</entry>
		<entry><parameter class="command">-x</parameter></entry>
	      </row>
	      <row>
		<entry>
		  Remove all ACL entries (except for the three
		  required entries).
		</entry>
		<entry><parameter class="command">-b</parameter></entry>
	      </row>
	      <row>
		<entry>Recalculate mask</entry>
		<entry>
		  Always recalculated, unless <parameter
		  class="command">-n</parameter> is used, or an mask
		  entry expicitly specified.
		</entry>
	      </row>
	      <row>
		<entry>Use ACL specification from a file</entry>
		<entry>
		  <parameter class="command">-M</parameter> (modify),
		  <parameter class="command">-X</parameter> (delete),
		  or <parameter class="command">--restore</parameter>
		</entry>
	      </row>
	      <row>
		<entry>Recursive modification of ACLs</entry>
		<entry><parameter class="command">-R</parameter></entry>
	      </row>
	    </tbody>
	  </tgroup>
	</table>

	<para>
	  As we have seen in the previous section, entries can be
	  specified for users and groups, by using the following
	  syntax:
	  <emphasis>user/group:name:permissions</emphasis>. Permissions
	  can be specified as a triplet by using the letters
	  <emphasis>r</emphasis> (read), <emphasis>w</emphasis>
	  (write), or <emphasis>x</emphasis> (execute). A dash
	  (<emphasis>-</emphasis>) should be used for permissions that
	  you do not want to give to the user or group, since Solaris
	  requires this. If you want to disallow access completely,
	  you can use the <emphasis>---</emphasis> triplet.
	</para>

	<para>
	  The specification for other users, and the mask
	  follows this format: <emphasis>other:r-x</emphasis>. The
	  following slightly more predictable format can also be
	  used: <emphasis>other::r-x</emphasis>.
	</para>

	<sect4 xml:id="chap-filesystem-permissions-acl-setting-modify">
	  <title>Modifying ACL entries</title>

	  <para>
	    The simplest operation is to modify an ACL entry. This
	    will create a new entry if the entry does not exist
	    yet. Entries can be modified with the <parameter
	    class="command">-m</parameter>. For instance, suppose that
	    we want to give the group <emphasis>friend</emphasis> read
	    and write access to the file
	    <filename>report.txt</filename>. This can be done with:
	  </para>

	  <screen>
$ <userinput>setfacl -m group:friends:rw- report.txt</userinput>
	  </screen>

	  <para>
	    The mask entry will be recalculated, setting it to the
	    union of all group entries, and additional user entries:
	  </para>

	  <screen>
$ <userinput>getfacl report.txt</userinput>
# file: report.txt
# owner: daniel
# group: daniel
user::rw-
group::r--
group:friends:rw-
mask::rw-
other::r--
	  </screen>

	  <para>
	    You can combine multiple ACL entries
	    by separating them with a comma character. For instance:
	  </para>

	  <screen>
$ <userinput>setfacl -m group:friends:rw-,group:foes:--- report.txt</userinput>
	  </screen>
	</sect4>

	<sect4 xml:id="chap-filesystem-permissions-acl-setting-removing">
	  <title>Removing ACL entries</title>

	  <para>
	    An entry can be removed with the <parameter
	    class="command">-x</parameter> option:
	  </para>

	  <screen>
$ <userinput>setfacl -x group:friends: report.txt</userinput>
	  </screen>

	  <para>
	    The trailing colon can optionally be omitted.
	  </para>
	</sect4>

	<sect4 xml:id="chap-filesystem-permissions-acl-setting-new">
	  <title>Making a new ACL</title>

	  <para>
	    The <parameter class="command">--set</parameter> option
	    is provided create a new access control list
	    for a file, clearing all existing entries,
	    except for the three required entries.
	    It is required that the file user, group and
	    other entries are also specified. For example:
	  </para>

	  <screen>
$ <userinput>setfacl --set user::rw-,group::r--,other:---,group:friends:rwx report.txt</userinput>
	  </screen>

	  <para>
	    If you do not want to clean the user, group, and other
	    permissions, but do want to clear all other ACL entries,
	    you can use the <parameter class="command">-b</parameter>
	    option. The following example uses this in combination
	    with the <parameter class="command">-m</parameter> option
	    to clear all ACL entries (except for user, group, and other),
	    and to add an entry for the <emphasis>friends</emphasis>
	    group:
	  </para>

	  <screen>
$ <userinput>setfacl -b -m group:friends:rw- report.txt</userinput>
	  </screen>
	</sect4>

	<sect4 xml:id="chap-filesystem-permissions-acl-setting-default">
	  <title>Setting a default ACL</title>

	  <para>
	    As we have seen in <xref
	    linkend="chap-filesystem-permissions-acl" />, directories
	    can have default ACL entries that specify what permissions
	    should be used for files and directories that are created
	    below that directory. The <parameter class="command">-d</parameter>
	    option is used to operate on default entries:
	  </para>

	  <screen>
$ <userinput>setfacl -d -m group:friends:rwx reports</userinput>
$ <userinput>getfacl reports</userinput>
# file: reports
# owner: daniel
# group: daniel
user::rwx
group::r-x
other::r-x
default:user::rwx
default:group::r-x
default:group:friends:rwx
default:mask::rwx
default:other::r-x
	  </screen>
	</sect4>

	<sect4 xml:id="chap-filesystem-permissions-acl-setting-filesource">
	  <title>Using an ACL from a reference file</title>

	  <para>
	    You can also use an ACL specification from file, rather
	    than specifying it on the command line. An input file follows
	    the same
	    syntax as specifying entries as a parameter to
	    <command>setfacl</command>, but the entries are separated
	    by newlines, rather than by commas. This is very useful,
	    because you can use the ACL for an existing file as a
	    reference:
	  </para>

	  <screen>
$ <userinput>getfacl report.txt > ref</userinput>
	  </screen>

	  <para>
	    The <parameter class="command">-M</parameter> option
	    is provided to modify the ACL for a
	    file by reading the entries from a file. So, if we have a
	    file named <filename>report2.txt</filename>, we could
	    modify the ACL for this file with the entries from
	    <filename>ref</filename> with:
	  </para>

	  <screen>
$ <userinput>setfacl -M ref report2.txt</userinput>
	  </screen>

	  <para>
	    If you would like to start with a clean ACL, and add the
	    entries from <filename>ref</filename>, you can add the
	    <parameter class="command">-b</parameter> flag that we
	    encountered earlier:
	  </para>

	  <screen>
$ <userinput>setfacl -b -M ref report2.txt</userinput>
	  </screen>

	  <para>
	    Of course, it is not necessary to use this interim
	    file. We can directly pipe the output from
	    <command>getfacl</command> to <command>setfacl</command>,
	    by using the symbolic name for the standard input
	    (<emphasis>-</emphasis>), rather than the name of a file:
	  </para>

	  <screen>
$ <userinput>getfacl report.txt | setfacl -b -M - report2.txt</userinput>
	  </screen>

	  <para>
	    The <parameter class="command">-X</parameter> removes
	    the ACL entries defined in a file. This follows the same syntax as the
	    <parameter class="command">-x</parameter> flag, with
	    commas replaced by newlines.
	  </para>
	</sect4>
      </sect3>
    </sect2>
  </sect1>

  <sect1 xml:id="chap-filesystem-finding">
    <title>Finding files</title>

    <sect2 xml:id="chap-filesystem-finding-find">
      <title>find</title>

      <para>
	The <command>find</command> command is without doubt the most
	comprehensive utility to find files on UNIX systems. Besides
	that it works in a simple and predictable way:
	<command>find</command> will traverse the directory tree or
	trees that are specified as a parameter to
	<command>find</command>. Besides that a user can specify an
	expression that will be evaluated for each file and directory.
	The name of a file or directory will be printed if the
	expression evaluates to <emphasis>true</emphasis>. The first
	argument that starts with a dash (<emphasis>-</emphasis>),
	exclamation mark (<emphasis>!</emphasis>, or an opening
	parenthesis (<emphasis>(</emphasis>, signifies the start of
	the expression. The expression can consist of various
	operands.  To wrap it up, the syntax of
	<command>find</command> is: <emphasis>find paths
	expression</emphasis>.
      </para>

      <para>
	The simplest use of <command>find</command> is to use no
	expression.  Since this matches every directory and subdirectory
	entry, all files and directories will be printed. For instance:
      </para>

      <screen>
$ <userinput>find .</userinput>
.
./economic
./economic/report.txt
./economic/report2.txt
./technical
./technical/report2.txt
./technical/report.txt
      </screen>

      <para>
	You can also specify multiple directories:
      </para>

      <screen>
$ <userinput>find economic technical</userinput>
economic
economic/report.txt
economic/report2.txt
technical
technical/report2.txt
technical/report.txt
      </screen>

      <sect3 xml:id="chap-filesystem-finding-find-nametype">
	<title>Operands that limit by object name or type</title>

	<para>
	  One common scenario for finding files or directories is to
	  look them up by name. The <emphasis>-name</emphasis> operand
	  can be used to match objects that have a certain name, or
	  match a particular wildcard. For instance, using the operand
	  <emphasis>-name 'report.txt'</emphasis> will only be true
	  for files or directories with the name
	  <filename>report.txt</filename>. For example:
	</para>

	<screen>
$ <userinput>find economic technical -name 'report.txt'</userinput>
economic/report.txt
technical/report.txt
	</screen>

	<para>
	  The same thing holds for wildcards:
	</para>

	<screen>
$ <userinput>find economic technical -name '*2.txt'</userinput>
economic/report2.txt
technical/report2.txt
	</screen>

	<note>
	  <para>
	    When using <command>find</command> you will want to pass
	    the wildcard to <command>find</command>, rather than
	    letting the shell expand it. So, make sure that patterns
	    are either quoted, or that wildcards are escaped.
	  </para>
	</note>

	<para>
	  It is also possible to evaluate the type of the object with
	  the <emphasis>-type c</emphasis> operand, where
	  <emphasis>c</emphasis> specifies the type to be matched.
	  <xref
	  linkend="chap-filesystem-finding-find-nametype-type-params"
	  /> lists the various object types that can be used.
	</para>

	<table xml:id="chap-filesystem-finding-find-nametype-type-params">
	  <title>Parameters for the '-type' operand</title>

	  <tgroup cols="2">
	    <thead>
	      <row>
		<entry>Parameter</entry><entry>Meaning</entry>
	      </row>
	    </thead>
	    <tbody>
	      <row>
		<entry>b</entry><entry>Block device file</entry>
	      </row>
	      <row>
		<entry>c</entry><entry>Character device file</entry>
	      </row>
	      <row>
		<entry>d</entry><entry>Directory</entry>
	      </row>
	      <row>
		<entry>f</entry><entry>Regular file</entry>
	      </row>
	      <row>
		<entry>l</entry><entry>Symbolic link</entry>
	      </row>
	      <row>
		<entry>p</entry><entry>FIFO</entry>
	      </row>
	      <row>
		<entry>s</entry><entry>Socket</entry>
	      </row>
	    </tbody>
	  </tgroup>
	</table>

	<para>
	  So, for instance, if you would like to match directories,
	  you could use the <emphasis>d</emphasis> parameter to
	  <emphasis>-type</emphasis> operand:
	</para>

	<screen>
$ <userinput>find . -type d</userinput>
.
./economic
./technical
	</screen>

	<para>
	  We will look at forming a complex expression at the end of
	  this section about <command>find</command>, but at this
	  moment it is handy to know that you can make a boolean 'and'
	  expression by specifying multiple operands. For instance
	  <emphasis>operand1 operand2</emphasis> is true if both
	  <emphasis>operand1</emphasis> and
	  <emphasis>operand2</emphasis> are true for the object that
	  is being evaluated. So, you could combine the
	  <emphasis>-name</emphasis> and <emphasis>-type</emphasis>
	  operands to find all directories that start with
	  <emphasis>eco</emphasis>:
	</para>

	<screen>
$ <userinput>find . -name 'eco*' -type d</userinput>
./economic
	</screen>
      </sect3>

      <sect3 xml:id="chap-filesystem-finding-find-perms">
	<title>Operands that limit by object ownership or permissions</title>

	<para>
	  Besides matching objects by their name or type, you can also
	  match them by their active permissions or the object ownership.
	  This is often useful to find files that have incorrect permissions
	  or ownership.
	</para>

	<para>
	  The owner (user) or group of an object can be matched with
	  respectively the <emphasis>-user username</emphasis> and
	  <emphasis>-group groupname</emphasis> variants. The name of
	  a user or group will be interpreted as a user ID or group ID
	  if the name is decimal, and could not be found on the system
	  with
	  <citerefentry><refentrytitle>getpwnam</refentrytitle><manvolnum>3</manvolnum></citerefentry>
	  or
	  <citerefentry><refentrytitle>getgrnam</refentrytitle><manvolnum>3</manvolnum></citerefentry>. So,
	  if you would like to match all objects of which
	  <emphasis>joe</emphasis> is the owner, you can use
	  <emphasis>-user joe</emphasis> as an operand:
	</para>

	<screen>
$ <userinput>find . -user joe</userinput>
./secret/report.txt
	</screen>

	<para>
	  Or to find all objects with the group
	  <emphasis>friend</emphasis> as the file group:
	</para>

	<screen>
$ <userinput>find . -group friends</userinput>
./secret/report.txt
	</screen>

	<para>
	  The operand for checking file permissions
	  <emphasis>-perm</emphasis> is less trivial. Like the
	  <command>chmod</command> command this operator can work with
	  octal and symbolic permission notations. We will start with
	  looking at the octal notation. If an octal number is
	  specified as a parameter to the <emphasis>-perm</emphasis>
	  operand, it will match all objects that have exactly that
	  permissions. For instance, <emphasis>-perm 0600</emphasis>
	  will match all objects that are only readable and writable
	  by the user, and have no additional flags set:
	</para>

	<screen>
$ <userinput>find . -perm 0600</userinput>
./secret/report.txt
	</screen>

	<para>
	  If a dash is added as a prefix to a number, it will match
	  every object that has at least the bits set that are
	  specified in the octal number. A useful example is to find
	  all files which have at least writable bits set for
	  <emphasis>other</emphasis> users with <emphasis>-perm
	  -0002</emphasis>. This can help you to find device nodes or
	  other objects with insecure permissions.
	</para>

	<screen>
$ <userinput>find /dev -perm -0002</userinput>
/dev/null
/dev/zero
/dev/ctty
/dev/random
/dev/fd/0
/dev/fd/1
/dev/fd/2
/dev/psm0
/dev/bpsm0
/dev/ptyp0
	</screen>

	<note>
	  <para>
	    Some device nodes have to be world-writable for a UNIX
	    system to function correctly. For instance, the
	    <filename>/dev/null</filename> device is always writable.
	  </para>
	</note>

	<para>
	  The symbolic notation of <emphasis>-perm</emphasis>
	  parameters uses the same notation as the
	  <command>chmod</command> command.  Symbolic permissions are
	  built with a file mode where all bits are cleared, so it is
	  never necessary to use a dash to take away rights. This also
	  prevents ambiguity that could arise with the dash
	  prefix. Like the octal syntax, prefixing the permission with
	  a dash will match objects that have at least the specified
	  permission bits set. The use of symbolic names is quite
	  predictable - the following two commands repeat the previous
	  examples with symbolic permissions:
	</para>

	<screen>
$ <userinput>find . -perm u+rw</userinput>
./secret/report.txt
	</screen>

	<screen>
$ <userinput>find /dev -perm -o+w</userinput>
/dev/null
/dev/zero
/dev/ctty
/dev/random
/dev/fd/0
/dev/fd/1
/dev/fd/2
/dev/psm0
/dev/bpsm0
/dev/ptyp0
	</screen>
      </sect3>

      <sect3 xml:id="chap-filesystem-finding-find-time">
	<title>Operands that limit by object creation time</title>

	<para>
	  There are three operands that operate on time intervals.
	  The syntax of the operand is <emphasis>operand n</emphasis>,
	  where <emphasis>n</emphasis> is the time in days. All three
	  operators calculate a time delta in seconds that is divided
	  by the the number of seconds in a day (86400), discarding
	  the remainder. So, if the delta is one day,
	  <emphasis>operand 1</emphasis> will match for the
	  object. The three operands are:
	</para>

	<itemizedlist>
	  <listitem>
	    <para>
	      <emphasis>-atime n</emphasis> - this operand evaluates
	      to true if the initialization time of <command>find</command>
	      minus the last access time of the object equals
	      to <emphasis>n</emphasis>.
	    </para>
	  </listitem>
	  <listitem>
	    <para>
	      <emphasis>-ctime n</emphasis> - this operand evaluates
	      to true if the initialization time of
	      <command>find</command> minus the time of the latest
	      change in the file status information equals to
	      <emphasis>n</emphasis>.
	    </para>
	  </listitem>
	  <listitem>
	    <para>
	      <emphasis>-mtime n</emphasis> - this operand evaluates
	      to true if the initialization time of
	      <command>find</command> minus the latest file change
	      time equals to <emphasis>n</emphasis>.
	    </para>
	  </listitem>
	</itemizedlist>

	<para>
	  So, these operands match if the latest access, change,
	  modification respectively was <emphasis>n</emphasis> days
	  ago. To give an example, the following command shows all
	  objects in <filename>/etc</filename> that have been modified
	  one day ago:
	</para>

	<screen>
$ <userinput>find /etc -mtime 1</userinput>
/etc
/etc/group
/etc/master.passwd
/etc/spwd.db
/etc/passwd
/etc/pwd.db
	</screen>

	<para>
	  The plus or minus sign can be used as modifiers for the meaning
	  of <emphasis>n</emphasis>. <emphasis>+n</emphasis> means more
	  than <emphasis>n</emphasis> days, <emphasis>-n</emphasis>
	  means less than <emphasis>n</emphasis> days. So, to find all
	  files in <filename>/etc</filename> that were modified less
	  than two days ago, you could execute:
	</para>

	<screen>
$ <userinput>find /etc -mtime -2</userinput>
/etc
/etc/network/run
/etc/network/run/ifstate
/etc/resolv.conf
/etc/default
/etc/default/locale
[...]
	</screen>

	<para>
	  Another useful time-based operand is the <emphasis>-newer
	  reffile</emphasis> operand. This matches all files that were
	  modified later that the file with filename
	  <filename>reffile</filename>. The following example shows how
	  you could use this to list all files that have later modification
	  times than <filename>economic/report2.txt</filename>:
	</para>

	<screen>
$ <userinput>find . -newer economic/report2.txt</userinput>
.
./technical
./technical/report2.txt
./technical/report.txt
./secret
./secret/report.txt
	</screen>
      </sect3>

      <sect3 xml:id="chap-filesystem-finding-find-depth">
	<title>Operands that affect tree traversal</title>

	<para>
	  Some operands affect the manner in which the
	  <command>find</command> command traverses the tree. The
	  first of these operands is the <emphasis>-xdev</emphasis>
	  operand. <emphasis>-xdev</emphasis> prevents that
	  <command>find</command> decends into directories that have a
	  different device ID, effectively avoiding traversal of other
	  filesystems. The directory to which the filesystem is
	  mounted, is printed, because this operand always returns
	  <emphasis>true</emphasis>. A nice example is a system where
	  <filename>/usr</filename> is mounted on a different filesystem
	  than <filename>/</filename>. For instance, if we search for
	  directories with the name <emphasis>bin</emphasis>, this may
	  yield the following result:
	</para>

	<screen>
$ <userinput>find / -name 'bin' -type d</userinput>
/usr/bin
/bin
	</screen>

	<para>
	  But if we add <emphasis>-xdev</emphasis>
	  <filename>/usr/bin</filename> is not found, because it is on
	  a different filesystem (and device):
	</para>

	<screen>
$ <userinput>find / -name 'bin' -type d -xdev</userinput>
/bin
	</screen>

	<para>
	  The <emphasis>-depth</emphasis> operand modifies the order
	  in which directories are evaluated. With
	  <emphasis>-depth</emphasis> the contents of a directory are
	  evaluated first, and then the directory itself. This can be
	  witnessed in the following example:
	</para>

	<screen>
$ <userinput>find . -depth</userinput>
./economic/report.txt
./economic/report2.txt
./economic
./technical/report2.txt
./technical/report.txt
./technical
.
	</screen>

	<para>
	  As you can see in the output, files in the
	  <emphasis>./economic</emphasis> directory is evaluated
	  before <filename>.</filename>, and
	  <filename>./economic/report.txt</filename> before
	  <filename>./economic</filename>. <emphasis>-depth</emphasis>
	  always evaluates to <emphasis>true</emphasis>.
	</para>

	<para>
	  Finally, the <emphasis>-prune</emphasis> operand causes find
	  not to decend into a directory that is being evaluated.
	  <emphasis>-prune</emphasis> is discarded if the
	  <emphasis>-depth</emphasis> operand is also
	  used. <emphasis>-depth</emphasis> always evaluates to
	  <emphasis>true</emphasis>.
	</para>
      </sect3>

      <sect3 xml:id="chap-filesystem-finding-find-exec">
	<title>Operands that execute external utilities</title>

	<para>
	  <command>find</command> becomes a very powerful tool when it
	  is combined with external utilities. This can be done with
	  the <emphasis>-exec</emphasis> operand. There are two
	  syntaxes for the <emphasis>-exec</emphasis> operand. The
	  first syntax is <emphasis>-exec utility arguments
	  ;</emphasis>. The command <emphasis>utility</emphasis> will
	  be executed with the arguments that were specified for each
	  object that is being evaluated. If any of the arguments is
	  <emphasis>{}</emphasis>, these braces will be replaced by
	  the file being evaluated. This is very handy, especially when
	  we consider that, if we use no additional expression syntax,
	  operands will be evaluated from left to right. Let's look at
	  an example:
	</para>

	<screen>
$ <userinput>find . -perm 0666 -exec chmod 0644 {} \;</userinput>
	</screen>

	<para>
	 The first operand returns true for files that have their
	 permissions set to <emphasis>0666</emphasis>. The second
	 operand executes <emphasis>chmod 0644 filename</emphasis> for
	 each file that is being evaluated. If you were wondering why
	 this command is not executed for every file, that is a good
	 question. Like many other interpreters of expressions,
	 <command>find</command> uses <quote>short-circuiting</quote>.
	 Because no other operator was specified, the logical
	 <emphasis>and</emphasis> operator is automatically is assumed
	 between both operands. If the first operand evaluates to
	 <emphasis>false</emphasis>, it makes no sense to evaluate any
	 further operands, because the complete expression will always
	 evaluate to false. So, the <emphasis>-exec</emphasis> operand
	 will only be evaluated if the first operand is true. Another
	 particularity is that the semi-colon that closes the
	 <emphasis>-exec</emphasis> is escaped, to prevent that the
	 shell parses it.
	</para>

	<para>
	  A nice thing about the <emphasis>-exec</emphasis> operator
	  is that it evaluates to <emphasis>true</emphasis> if the
	  command terminated sucessfully. So, you could also use
	  the <emphasis>-exec</emphasis> command to add additional
	  conditions that are not represented by <command>find</command>
	  operands. For instance, the following command prints
	  all objects ending with <emphasis>.txt</emphasis> that contain
	  the string <emphasis>gross income</emphasis>:
	</para>

	<screen>
$ <userinput>find . -name '*.txt' -exec grep -q 'gross income' {} \; -print</userinput>
./economic/report2.txt
	</screen>

	<para>
	  The <command>grep</command> command will be covered later on.
	  <!-- XXX - xref --> But for the moment, it is enough to know
	  that it can be used to match text patterns. The
	  <emphasis>-print</emphasis> operand prints the current
	  object path. It is always used implicitly, except when the
	  <emphasis>-exec</emphasis> or <emphasis>-ok</emphasis>
	  operands are used. <!-- XXX - move to introduction? -->
	</para>

	<para>
	  The second syntax of the <emphasis>-exec</emphasis> operand
	  is <emphasis>-exec utility arguments {} +</emphasis>. This
	  gathers a set of all matched object for which the expression
	  is true, and provides this set of files as an argument to
	  the utility that was specified. The first example of the
	  <emphasis>-exec</emphasis> operand can also be written as:
	</para>

	<screen>
$ <userinput>find . -perm 0666 -exec chmod 0644 {} +</userinput>
	</screen>

	<para>
	  This will execute the <command>chmod</command> command only
	  once, with all files for which the expression is true as its
	  arguments. This operand always returns <emphasis>true</emphasis>.
	</para>

	<para>
	  If a command executed by find returns a non-zero value
	  (meaning that the execution of the command was not
	  succesful), <command>find</command> should also return a
	  non-zero value.
	</para>
      </sect3>

      <sect3 xml:id="chap-filesystem-finding-find-operators">
	<title>Operators for building complex expressions</title>

	<para>
	  <command>find</command> provides some operators that can be
	  combined to make more complex expressions:
	</para>

	<variablelist>
	  <title>Operators</title>

	  <varlistentry>
	    <term>( expr )</term>
	    <listitem>
	      <para>
		Evaluates to <emphasis>true</emphasis> if
		<emphasis>expr</emphasis> evaluates to
		<emphasis>true</emphasis>.
	      </para>
	    </listitem>
	  </varlistentry>
	  <varlistentry>
	    <term>expr1 [-a] expr2</term>
	    <listitem>
	      <para>
		Evaluates to <emphasis>true</emphasis> if both
		<emphasis>expr1</emphasis> and <emphasis>expr2</emphasis>
		are true. If <emphasis>-a</emphasis> is omitted,
		this operator is implicitly assumed.
	      </para>

	      <para>
		<command>find</command> will use short-circuiting when
		this operator is evaluated: <emphasis>expr2</emphasis>
		will not be evaluated when <emphasis>expr1</emphasis>
		evaluates to <emphasis>false</emphasis>
	      </para>
	    </listitem>
	  </varlistentry>
	  <varlistentry>
	    <term>expr1 -o expr2</term>
	    <listitem>
	      <para>
		Evaluates to <emphasis>true</emphasis> if either or
		both <emphasis>expr1</emphasis> and
		<emphasis>expr2</emphasis> are true.
	      </para>

	      <para>
		<command>find</command> will use short-circuiting when
		this operator is evaluated: <emphasis>expr2</emphasis>
		will not be evaluated when <emphasis>expr1</emphasis>
		evaluates to <emphasis>true</emphasis>
	      </para>
	    </listitem>
	  </varlistentry>
	  <varlistentry>
	    <term>! expr</term>
	    <listitem>
	      <para>
		Negates <emphasis>expr</emphasis>. So, if
		<emphasis>expr</emphasis> evaluates to true, this
		expression will evaluate to <emphasis>false</emphasis>
		and vise versa.
	      </para>
	    </listitem>
	  </varlistentry>
	</variablelist>

	<para>
	  Since both the parentheses and exclamation mark characters
	  are interpreted by most shells, they should usually be
	  escaped.
	</para>

	<para>
	  The following example shows some operators in action. This
	  command executes <command>chmod</command> for all files that
	  either have their permissions set to
	  <emphasis>0666</emphasis> or <emphasis>0664</emphasis>.
	</para>

	<screen>
$ <userinput>find . \( -perm 0666 -o -perm 0664 \) -exec chmod 0644 {} \;</userinput>
	</screen>
      </sect3>
    </sect2>

    <sect2 xml:id="chap-filesystem-finding-which">
      <title>which</title>

      <para>
	The <command>which</command> command is not part of the Single
	UNIX Specification version 3, but it is provided by most
	sysmtems. <command>which</command> locates a command that is
	in the user's path (as set by the PATH environment variable),
	printing its full path. Providing the name of a command as its
	parameter will show the full path:
      </para>

      <screen>
$ <userinput>which ls</userinput>
/bin/ls
      </screen>

      <para>
	You can also query the paths of multiple commands:
      </para>

      <screen>
$ <userinput>which ls cat</userinput>
/bin/ls
/bin/cat
      </screen>

      <para>
        <command>which</command> returns a non-zero return value
	if the command could not be found.
      </para>
    </sect2>

    <sect2 xml:id="chap-filesystem-finding-whereis">
      <title>whereis</title>

      <para>
	This <command>whereis</command> command searches binaries, manual pages and sources of a
	command in some predefined places. For instance, the following
	command shows the path of the <command>ls</command> and the
	<citerefentry><refentrytitle>ls</refentrytitle><manvolnum>1</manvolnum></citerefentry>
	manual page:
      </para>

      <screen>
$ <userinput>whereis ls</userinput>
ls: /bin/ls /usr/share/man/man1/ls.1.gz
      </screen>
    </sect2>

    <sect2 xml:id="chap-filesystem-finding-locate">
      <title>locate</title>

      <para>
        Slackware Linux also provides the
	<command>locate</command> command that searches through a file
	database that can be generated periodically with the
	<command>updatedb</command> command. Since it uses a prebuilt
	database of the filesystem, it is a lot faster than
	<command>command</command>, especially when directory entry
	information has not been cached yet. Though, the
	<command>locate</command>/<command>updatedb</command> combo
	has some downsides:
      </para>

      <itemizedlist>
	<listitem>
	  <para>
	    New files are not part of the database until the next
	    <command>updatedb</command> invocation.
	  </para>
	</listitem>
	<listitem>
	  <para>
	    <command>locate</command> has no conception of
	    permissions, so users may locate files that are normally
	    hidden to them.
	  </para>
	</listitem>
	<listitem>
	  <para>
	    A newer implementation, named <emphasis>slocate</emphasis>
	    deals with permissions, but requires elevated privileges.
	    This is the <command>locate</command> variation that is
	    included with Slackware Linux.
	  </para>
	</listitem>
      </itemizedlist>

      <para>
	With filesystems becoming faster, and by applying common sense
	when formulating <command>find</command> queries,
	<command>locate</command> does not really seem worth the
	hassle. Of course, your mileage may vary. That said, the basic
	usage of <command>locate</command> is <emphasis>locate
	filename</emphasis>. For example:
      </para>

      <screen>
$ <userinput>locate locate</userinput>
/usr/bin/locate
/usr/lib/locate
/usr/lib/locate/bigram
/usr/lib/locate/code
/usr/lib/locate/frcode
[...]
      </screen>

    </sect2>
  </sect1>

  <sect1 xml:id="basics-filesystem-archives">
    <title>Archives</title>

    <sect2 xml:id="basics-filesystem-archives-introduction">
      <title>Introduction</title>

      <para>
	Sooner or later a GNU/Linux user will encounter
	<acronym>tar</acronym> archives, tar is the standard format
	for archiving files on GNU/Linux.  It is often used in
	conjunction with <command>gzip</command> or
	<command>bzip2</command>. Both commands can compress files and
	archives.  <xref linkend="archive-extentions" /> lists
	frequently used archive extensions, and what they mean.
      </para>

      <table xml:id="archive-extentions">
	<title>Archive file extensions</title>
	<tgroup cols="2" align="left" colsep="1" rowsep="1">
	  <thead>
	    <row>
	      <entry>Extension</entry>
	      <entry>Meaning</entry>
	    </row>
	  </thead>
	  <tbody>
	    <row>
	      <entry>.tar</entry>
	      <entry>An uncompressed tar archive</entry>
	    </row>
	    <row>
	      <entry>.tar.gz</entry>
	      <entry>A tar archive compressed with gzip</entry>
	    </row>
	    <row>
	      <entry>.tgz</entry>
	      <entry>A tar archive compressed with gzip</entry>
	    </row>
	    <row>
	      <entry>.tar.bz2</entry>
	      <entry>A tar archive compressed with bzip2</entry>
	    </row>
	    <row>
	      <entry>.tbz</entry>
	      <entry>A tar archive compressed with bzip2</entry>
	    </row>
	  </tbody>
	</tgroup>
      </table>

      <para>
	The difference between <command>bzip2</command> and
	<command>gzip</command> is that <command>bzip2</command> can
	find repeating information in larger blocks, resulting in
	better compression. But <command>bzip2</command> is also a lot
	slower, because it does more data analysis.
      </para>
    </sect2>

    <sect2 xml:id="basics-filesystem-archives-extracting">
      <title>Extracting archives</title>

      <para>
	Since many software and data in the GNU/Linux world is
	archived with <command>tar</command> it is important to get
	used to extracting tar archives. The first thing you will
	often want to do when you receive a tar archive is to list its
	contents. This can be achieved by using the <parameter
	class="command">t</parameter> parameter. However, if we just
	execute <command>tar</command> with this parameter and the
	name of the archive it will just sit and wait until you enter
	something to the standard input:
      </para>

      <screen>
$ <userinput>tar t test.tar</userinput>
      </screen>

      <para>
	This happens because <command>tar</command> reads data from
	its standard input. If you forgot how redirection works, it is
	a good idea to reread <xref linkend="chap-shell-inout" />. Let's
	see what happens if we redirect our tar archive to tar:
      </para>

      <screen>
$ <userinput>tar t &lt; test.tar</userinput>
test/
test/test2
test/test1
      </screen>

      <para>
	That looks more like the output you probably expected. This
	archive seems to contain a directory
	<filename>test</filename>, which contains the files
	<filename>test2</filename> and <filename>test2</filename>.  It
	is also possible to specify the archive file name as an
	parameter to <command>tar</command>, by using the <parameter
	class="command">f</parameter> parameter:
      </para>

      <screen>
$ <userinput>tar tf test.tar</userinput>
test/
test/test2
test/test1
      </screen>

      <para>
	This looks like an archive that contains useful files ;). We
	can now go ahead, and extract this archive by using the
	<parameter class="command">x</parameter> parameter:
      </para>

      <screen>
$ <userinput>tar xf test.tar</userinput>
      </screen>

      <para>
	We can now verify that tar really extracted the archive by
	listing the contents of the directory with
	<command>ls</command>:
      </para>

      <screen>
$ <userinput>ls test/</userinput>
test1  test2
      </screen>

      <para>
	Extracting or listing files from a gzipped or bzipped archive
	is not much more difficult. This can be done by adding a
	<parameter class="command">z</parameter> or <parameter
	class="command">j</parameter> for respectively archives
	compressed with <command>gzip</command> or
	<command>bzip2</command>.  For example, we can list the
	contents of a gzipped archive with:
      </para>

      <screen>
$ <userinput>tar ztf archive2.tar.gz</userinput>
      </screen>

      <para>
	And a bzipped archive can be extracted with:
      </para>

      <screen>
$ <userinput>tar jxf archive3.tar.bz2</userinput>
      </screen>
    </sect2>

    <sect2 xml:id="basics-filesystem-archives-creating">
      <title>Creating archives</title>

      <para>
	You can create archives with the <parameter
	class="command">c</parameter> parameter. Suppose that we have
	the directory <filename>test</filename> shown in the previous
	example. We can make an archive with the
	<filename>test</filename> directory and the files in this
	directory with:
      </para>

      <screen>
$ <userinput>tar cf important-files.tar test</userinput>
      </screen>

      <para>
	This will create the <filename>important-files.tar</filename>
	archive (which is specified with the <parameter
	class="command">f</parameter> parameter). We can now verify
	the archive:
      </para>

      <screen>
$ <userinput>tar tf important-files.tar</userinput>
test/
test/test2
test/test1
      </screen>

      <para>
	Creating a gzipped or bzipped archive goes along the same
	lines as extracting compressed archives: add a <parameter
	class="command">z</parameter> for gzipping an archive, or
	<parameter class="command">b</parameter> for bzipping an
	archive. Suppose that we wanted to create a
	<command>gzip</command> compressed version of the archive
	created above. We can do this with:
      </para>

      <screen>
<userinput>tar zcf important-files.tar.gz test</userinput>
      </screen>
    </sect2>
  </sect1>

  <sect1 xml:id="basics-filesystem-mounting">
    <title>Mounting filesystems</title>

    <sect2 xml:id="basics-filesystem-mounting-introduction">
      <title>Introduction</title>

      <para>
	Like most Unices Linux uses a technique named
	<quote>mounting</quote> to access filesystems. Mounting means
	that a filesystem is connected to a directory in the root
	filesystem. One could for example mount a CD-ROM drive to the
	<filename>/mnt/cdrom</filename> directory. Linux supports many
	kinds of filesystems, like Ext2, Ext3, ReiserFS, JFS, XFS,
	ISO9660 (used for CD-ROMs), UDF (used on some DVDs) and
	DOS/Windows filesystems, like FAT, FAT32 and NTFS. These
	filesystems can reside on many kinds of media, for example
	hard drives, CD-ROMs and Flash drives. This section explains
	how filesystems can be mounted and unmounted.
      </para>
    </sect2>

    <sect2 xml:id="basics-filesystem-mounting-mount">
      <title>mount</title>

      <para>
	The <command>mount</command> is used to mount filesystems. The
	basic syntax is: <quote>mount /dev/devname
	/mountpoint</quote>. The device name can be any block device,
	like hard disks or CD-ROM drives. The mount point can be an
	arbitrary point in the root filesystem. Let's look at an
	example:
      </para>

      <screen>
# <userinput>mount /dev/cdrom /mnt/cdrom</userinput>
      </screen>

      <para>
	This mounts the <filename>/dev/cdrom</filename> on the
	<filename>/mnt/cdrom</filename> mountpoint. The
	<filename>/dev/cdrom</filename> device name is normally a link
	to the real CD-ROM device name (for example,
	<filename>/dev/hdc</filename>). As you can see, the concept is
	actually very simple, it just takes some time to learn the
	device names ;). Sometimes it is necessary to specify which
	kind of filesystem you are trying to mount.  The filesystem
	type can be specified by adding the <parameter
	class="command">-t</parameter> parameter:
      </para>

      <screen>
# <userinput>mount -t vfat /dev/sda1 /mnt/flash</userinput>
      </screen>

      <para>
	This mounts the vfat filesystem on
	<filename>/dev/sda1</filename> to
	<filename>/mnt/flash</filename>.
      </para>
    </sect2>

    <sect2 xml:id="basics-filesystem-mounting-umount">
      <title>umount</title>

      <para>
	The <command>umount</command> command is used to unmount
	filesystems.  <command>umount</command> accepts two kinds of
	parameters, mount points or devices. For example:
      </para>

      <screen>
# <userinput>umount /mnt/cdrom</userinput>
# <userinput>umount /dev/sda1</userinput>
      </screen>

      <para>
	The first command unmounts the filesystem that was mounted on
	<filename>/mnt/cdrom</filename>, the second commands unmounts
	the filesystem on <filename>/dev/sda1</filename>.
      </para>
    </sect2>

    <sect2 xml:id="basics-filesystem-mounting-fstab">
      <title>The fstab file</title>

      <para>
	The GNU/Linux system has a special file,
	<filename>/etc/fstab</filename>, that specifies which
	filesystems should be mounted during the system boot.  Let's
	look at an example:
      </para>

      <screen>
/dev/hda10       swap             swap        defaults         0   0
/dev/hda5        /                xfs         defaults         1   1
/dev/hda6        /var             xfs         defaults         1   2
/dev/hda7        /tmp             xfs         defaults         1   2
/dev/hda8        /home            xfs         defaults         1   2
/dev/hda9        /usr             xfs         defaults         1   2
/dev/cdrom       /mnt/cdrom       iso9660     noauto,owner,ro  0   0
/dev/fd0         /mnt/floppy      auto        noauto,owner     0   0
devpts           /dev/pts         devpts      gid=5,mode=620   0   0
proc             /proc            proc        defaults         0   0
      </screen>

      <para>
	As you can see each entry in the <filename>fstab</filename>
	file has five entries: fs_spec, fs_file, fs_vfstype,
	fs_mntops, fs_freq, and fs_passno.  We are now going to look
	at each entry.
      </para>

      <sect3>
	<title>fs_spec</title>

	<para>
	  The fs_spec option specifies the block device, or remote
	  filesystem that should be mounted. As you can see in the
	  example several /dev/hda partitions are specified, as well
	  as the CD-ROM drive and floppy drive. When NFS volumes are
	  mounted an IP address and directory can be specified, for
	  example: <filename>192.168.1.10:/exports/data</filename>.
	</para>
      </sect3>

      <sect3>
	<title>fs_file</title>

	<para>
	  fs_file specifies the mount point. This can be an arbitrary
	  directory in the filesystem.
	</para>
      </sect3>

      <sect3>
	<title>fs_vfstype</title>

	<para>
	  This option specifies what kind of filesystem the entry
	  represents. For example this can be: ext2, ext3, reiserfs,
	  xfs, nfs, vfat, or ntfs.
	</para>
      </sect3>

      <sect3>
	<title>fs_mntops</title>

	<para>
	  The fs_mntops option specifies which parameters should be
	  used for mounting the filesystem. The
	  <command>mount</command> manual page has an extensive
	  description of the available options. These are the most
	  interesting options:
	</para>

	<itemizedlist>
	  <listitem>
	    <para>
	      <emphasis>noauto</emphasis>: filesystems that are listed
	      in <filename>/etc/fstab</filename> are normally mounted
	      automatically. When the <quote>noauto</quote> option is
	      specified, the filesystem will not be mounted during the
	      system boot, but only after issuing a
	      <command>mount</command> command. When mounting such
	      filesystem, only the mount point or device name has to
	      be specified, for example: <command>mount
	      /mnt/cdrom</command>
	    </para>
	  </listitem>
	  <listitem>
	    <para>
	      <emphasis>user</emphasis>: adding the
	      <quote>user</quote> option will allow normal users to
	      mount the filesystem (normally only the superuser is
	      allowed to mount filesystems).
	    </para>
	  </listitem>
	  <listitem>
	    <para>
	      <emphasis>owner</emphasis>: the <quote>owner</quote>
	      option will allow the owner of the specified device to
	      mount the specified device. You can see the owner of a
	      device using <command>ls</command>, e.g.  <command>ls -l
	      /dev/cdrom</command>.
	    </para>
	  </listitem>
	  <listitem>
	    <para>
	      <emphasis>noexec</emphasis>: with this option enabled
	      users can not run files from the mounted
	      filesystem. This can be used to provide more security.
	    </para>
	  </listitem>
	  <listitem>
	    <para>
	      <emphasis>nosuid</emphasis>: this option is comparable
	      to the <quote>noexec</quote> option. With
	      <quote>nosuid</quote> enabled SUID bits on files on the
	      filesystem will not be allowed. SUID is used for certain
	      binaries to provide a normal user to do something
	      privileged.  This is certainly a security threat, so
	      this option should really be used for removable media,
	      etc. A normal user mount will force the nosuid option,
	      but a mount by the superuser will not!
	    </para>
	  </listitem>
	  <listitem>
	    <para>
	      <emphasis>unhide</emphasis>: this option is only
	      relevant for normal CD-ROMs with the ISO9660
	      filesystem. If <quote>unhide</quote> is specified hidden
	      files will also be visible.
	    </para>
	  </listitem>
	</itemizedlist>
      </sect3>

      <sect3>
	<title>fs_freq</title>

	<para>
	  If the <quote>fs_freq</quote> is set to 1 or higher, it
	  specifies after how many days a filesystem dump (backup) has
	  to be made. This option is only used when <ulink
	  url="http://dump.sourceforge.net/">dump</ulink> is
	  installed, and set up correctly to handle this.
	</para>
      </sect3>

      <sect3>
	<title>fs_passno</title>

	<para>
	  This field is used by <command>fsck</command> to determine
	  the order in which filesystems are checked during the system
	  boot.
	</para>
      </sect3>
    </sect2>

  </sect1>

  <sect1 xml:id="basics-filesystem-gnupg">
    <title>Encrypting and signing files</title>

    <sect2>
      <title>Introduction</title>

      <para>
	There are two security mechanisms for securing files: signing
	files and encrypting files. Signing a file means that a
	special digital signature is generated for a file. You, or
	other persons can use the signature to verify the integrity of
	the file. File encryption encodes a file in a way that only a
	person for which the file was intended to read can read the
	file.
      </para>

      <para>
	This system relies on two keys: the private and the public
	key. Public keys are used to encrypt files, and files can only
	be decrypted with the private key. This means that one can
	sent his public key out to other persons. Others can use this
	key to send encrypted files, that only the person with the
	private key can decode. Of course, this means that the
	security of this system depends on how well the private is
	kept secret.
      </para>

      <para>
	Slackware Linux provides an excellent tool for signing and
	encrypting files, named GnuPG. GnuPG can be installed from the
	<quote>n</quote> disk set.
      </para>
    </sect2>

    <sect2>
      <title>Generating your private and public keys</title>

      <para>
	Generating public and private keys is a bit complicated,
	because GnuPG uses DSA keys by default. DSA is an encryption
	algorithm, the problem is that the maximum key length of DSA
	is 1024 bits, this is considered too short for the longer
	term. That is why it is a good idea to use 2048 bit RSA
	keys. This section describers how this can be done.
      </para>

      <note>
	<para>
	  1024-bit keys were believed to be secure for a long
	  time. But Bernstein's paper <emphasis>Circuits for Integer
	  Factorization: a Proposal</emphasis> contests this, the
	  bottom line is that it is quite feasible for national
	  security agencies to produce hardware that can break keys in
	  a relatively short amount of time.  Besides that it has be
	  shown that 512-bit RSA keys can be broken in a relatively
	  short time using common hardware. More information about
	  these issues can by found in this e-mail to the cypherpunks
	  list:
	<ulink url="http://lists.saigon.com/vault/security/encryption/rsa1024.html" />
	</para>
      </note>

      <para>
	We can generate a key by executing:
      </para>

      <screen>
$ <userinput>gpg --gen-key</userinput>
      </screen>

      <para>
	The first question is what kind of key you would like to
	make. We will choose <emphasis>(4) RSA (sign only)</emphasis>:
      </para>

      <screen>
Please select what kind of key you want:
   (1) DSA and ElGamal (default)
   (2) DSA (sign only)
   (4) RSA (sign only)
Your selection? <userinput>4</userinput>
      </screen>

      <para>
	You will then be asked what the size of the key you want to
	generate has to be. Type in <emphasis>2048</emphasis> to
	generate a 2048 bit key, and press enter to continue.
      </para>

      <screen>
What keysize do you want? (1024) <userinput>2048</userinput>
      </screen>

      <para>
	The next question is simple to answer, just choose what you
	like. Generally speaking it is not a bad idea to let the key
	be valid infinitely. You can always deactivate the key with a
	special revocation certificate.
      </para>

      <screen>
Please specify how long the key should be valid.
         0 = key does not expire
      &lt;n&gt;  = key expires in n days
      &lt;n&gt;w = key expires in n weeks
      &lt;n&gt;m = key expires in n months
      &lt;n&gt;y = key expires in n years
Key is valid for? (0) <userinput>0</userinput>
      </screen>

      <para>
	GnuPG will then ask for confirmation. After confirming your
	name and e-mail address will be requested. GnuPG will also ask
	for a comment, you can leave this blank, or you could fill in
	something like <quote>Work</quote> or <quote>Private</quote>,
	to indicate what the key is used for. For example:
      </para>

      <screen>
Real name: <userinput>John Doe</userinput>
Email address: <userinput>john@doe.com</userinput>
Comment: <userinput>Work</userinput>              
You selected this USER-ID:
    "John Doe (Work) &lt;john@doe.com&gt;"
      </screen>

      <para>
	GnuPG will the ask you to confirm your user ID. After
	confirming it GnuPG will ask you to enter a password. Be sure
	to use a good password:
      </para>

      <screen>
You need a Passphrase to protect your secret key.    

Enter passphrase:
      </screen>

      <para>
	After entering the password twice GnuPG will generate the
	keys. But we are not done yet. GnuPG has only generated a key
	for signing information, not for encryption of information. To
	continue, have a look at the output, and look for the key
	ID. In the information about the key you will see
	<emphasis>pub 2048R/</emphasis>. The key ID is printed after
	this fragment.  In this example:
      </para>

      <screen>
public and secret key created and signed.
key marked as ultimately trusted.

pub  2048R/8D080768 2004-07-16 John Doe (Work) &lt;john@doe.com&gt;
     Key fingerprint = 625A 269A 16B9 C652 B953  8B64 389A E0C9 8D08 0768
      </screen>

      <para>
	the key ID is <emphasis>8D080768</emphasis>. If you lost the
	output of the key generation you can still find the key ID in
	the output of the <command>gpg --list-keys</command>
	command. Use the key ID to tell GnuPG that you want to edit
	your key:
      </para>

      <screen>
$ <userinput>gpg --edit-key &lt;Key ID&gt;</userinput>
      </screen>

      <para>
	With the example key above the command would be:
      </para>

      <screen>
$ <userinput>gpg --edit-key 8D080768</userinput>
      </screen>

      <para>
	GnuPG will now display a command prompt. Execute the
	<command>addkey</command> command on this command prompt:
      </para>

      <screen>
Command&gt; <userinput>addkey</userinput>
      </screen>

      <para>
	GnuPG will now ask the password you used for your key:
      </para>

      <screen>
Key is protected.

You need a passphrase to unlock the secret key for
user: "John Doe (Work) &lt;john@doe.com&gt;"
2048-bit RSA key, ID 8D080768, created 2004-07-16

Enter passphrase:
      </screen>

      <para>
	After entering the password GnuPG will ask you what kind of
	key you would like to create. Choose <emphasis>RSA (encrypt
	only)</emphasis>, and fill in the information like you did
	earlier (be sure to use a 2048 bit key).  For example:
      </para>

      <screen>
Please select what kind of key you want:
   (2) DSA (sign only)
   (3) ElGamal (encrypt only)
   (4) RSA (sign only)
   (5) RSA (encrypt only)
Your selection? <userinput>5</userinput>
What keysize do you want? (1024) <userinput>2048</userinput>
Requested keysize is 2048 bits       
Please specify how long the key should be valid.
         0 = key does not expire
      &lt;n&gt;  = key expires in n days
      &lt;n&gt;w = key expires in n weeks
      &lt;n&gt;m = key expires in n months
      &lt;n&gt;y = key expires in n years
Key is valid for? (0) <userinput>0</userinput>
      </screen>

      <para>
	And confirm that the information is correct. After the key is
	generated you can leave the GnuPG command prompt, and save the
	new key with the <command>save</command> command:
      </para>

      <screen>
Command&gt; <userinput>save</userinput>
      </screen>

      <para>
	Congratulations! You have now generated the necessary keys to
	encrypt and decrypt e-mails and files. You can now configure
	your e-mail client to use GnuPG. It is a good idea to store
	the contents of the <filename>.gnupg</filename> directory on
	some reliable medium, and store that in a safe place! If your
	private key is lost you can't decrypt files and messages that
	were encrypted with your public key. If the private key, and
	your password are stolen, the security of this system is
	completely compromised.
      </para>
    </sect2>

    <sect2>
      <title>Exporting your public key</title>

      <para>
	To make GnuPG useful, you have to give your public key to
	people who send you files or e-mails. They can use your public
	key to encrypt files, or use it to verify whether a file has a
	correct signature or not. The key can be exported using the
	<parameter class="command">--export</parameter> parameter. It
	is also a good idea to specify the <parameter
	class="command">--output</parameter> parameter, this will save
	the key in a file. The following command would save the public
	key of <emphasis>John Doe</emphasis>, used in earlier
	examples, to the file <filename>key.gpg</filename>:
      </para>

      <screen>
$ <userinput>gpg --output key.gpg --export john@doe.com</userinput>
      </screen>

      <para>
	This saves the key in binary format. Often it is more
	convenient to use the so-called <quote>ASCII armored
	output</quote>, which fits better for adding the key to
	e-mails, or websites. You export an ASCII armored version of
	the key by adding the <parameter
	class="command">--armor</parameter> parameter:
      </para>

      <screen>
$ <userinput>gpg --armor --output key.gpg --export john@doe.com</userinput>
      </screen>

      <para>
	If you look at the <filename>key.gpg</filename> file you will
	notice that the ASCII armored key is a much more comfortable
	format.
      </para>
    </sect2>

    <sect2>
      <title>Signatures</title>

      <para>
	With GPG you can make a signature for a file. This signature
	is unique, because your signature can only be made with your
	private key. This means that other people can check whether
	the file was really sent by you, and whether it was in any way
	altered or not. Files can be signed with the <parameter
	class="command">--detach-sign</parameter> parameter. Let us
	look at an example. This command will make a signature for the
	<filename>memo.txt</filename> file. The signature will be
	stored in <filename>memo.txt.sig</filename>.
      </para>

      <screen>
$ <userinput>gpg --output memo.txt.sig --detach-sign memo.txt</userinput>

You need a passphrase to unlock the secret key for
user: "John Doe (Work) &lt;john@doe.com&gt;"
2048-bit RSA key, ID 8D080768, created 2004-07-16

Enter passphrase:
      </screen>

      <para>
	As you can see, GnuPG will ask you to enter the password for
	your private key. After you have entered the right key the
	signature file (<filename>memo.txt.sig</filename>) will be
	created.
      </para>

      <para>
	You can verify a file with its signature using the <parameter
	class="command">--verify</parameter> parameter. Specify the
	signature file as a parameter to the <parameter
	class="command">--verify</parameter> parameter. The file that
	needs to be verified can be specified as the final parameter:
      </para>

      <screen>
$ <userinput>gpg --verify memo.txt.sig memo.txt</userinput>
gpg: Signature made Tue Jul 20 23:47:45 2004 CEST using RSA key ID 8D080768
gpg: Good signature from "John Doe (Work) &lt;john@doe.com&gt;"
      </screen>

      <para>
	This will confirm that the file was indeed signed by
	<emphasis>John Doe (Work) &lt;john@doe.com&gt;</emphasis>,
	with the key <emphasis>8D080768</emphasis>, and that the file
	is unchanged. Suppose the file was changed, GnuPG would have
	complained about it loudly:
      </para>

      <screen>
$ <userinput>gpg --verify memo.txt.sig memo.txt</userinput>
gpg: Signature made Tue Jul 20 23:47:45 2004 CEST using RSA key ID 8D080768
gpg: BAD signature from "John Doe (Work) &lt;john@doe.com&gt;"
      </screen>
    </sect2>

    <sect2>
      <title>Encryption</title>

      <para>
	One of the main features of GnuPG is encryption. Due to its
	use of asymmetric cryptography, the person who encrypts a file
	and the person who decrypts a file do not need to share a
	key. You can encrypt a file with the public key of another
	person, and that other person can decrypt it with his or her
	private key. You can encrypt files with the <parameter
	class="command">--encrypt</parameter>. If you do not specify a
	user ID for which the file should be encrypted, GnuPG will
	prompt for the user ID. You can specify the user ID with the
	<parameter class="command">-r</parameter> parameter. In the
	following example, the file <filename>secret.txt</filename>
	will be encrypted for another person named <emphasis>John
	Doe</emphasis>:
      </para>

      <screen>
$ <userinput>gpg --encrypt -r "John Doe" secret.txt</userinput>
      </screen>

      <para>
	The user ID is quoted with double quotes for making sure that
	the ID is interpreted as a single program argument. After the
	encryption is completed, the encrypted version of the file
	will be available as <filename>secret.txt.gpg</filename>.
      </para>

      <para>
	The user who receives the file can decrypt it with the
	<parameter class="command">--decrypt</parameter> parameter of
	the <command>gpg</command> command:
      </para>

      <screen>
$ <userinput>gpg --output secret.txt --decrypt secret.txt.gpg</userinput>

You need a passphrase to unlock the secret key for
user: "John Doe (Work) &lt;john@doe.com&gt;"
2048-bit RSA key, ID 8D080768, created 2004-07-16 (main key ID EC3ED1AB)

Enter passphrase:

gpg: encrypted with 2048-bit RSA key, ID 8D080768, created 2004-07-16
      "John Doe (Work) &lt;john@doe.com&gt;"
      </screen>

      <para>
	In this example the <parameter
	class="command">--output</parameter> parameter is used store
	the decrypted content in <filename>secret.txt</filename>.
      </para>
    </sect2>
  </sect1>
</chapter>
